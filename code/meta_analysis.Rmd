---
output: html_document
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 80
---

```{=html}
<style type="text/css">
.main-container {
  max-width: 800px;
  margin-left: auto;
  margin-right: auto;
}
</style>
```


# Dung beetles increase plant growth: a meta-analysis

Our two aims with this project are to conduct a systematic review and then meta-analysis to assess:<br>

1) When dung beetles access dung, does plant growth increase in the immediate area?<br>

2) Are there ecological and experimental factors (moderators) that influence this plant growth?<br>
<br>

```{r Load libraries and set parent directory}
#| include: false
#| message: false
#| warning: false

# Load libraries
library("broom")
library("dmetar")
library("dplyr")
library("here")
library("knitr")
library("matrixcalc")
library("metaAidR")
library("metafor")
library("multcompView")
library("orchaRd")   # github.com/itchyshin/orchard_plot
library("readxl")
library("tidyverse")
library("wesanderson")

# Set the parent directory so that the relative paths used later work properly
here()   
```

Our statistical analysis was largely influenced by supplementary material of Bishop and Nakagawa (2021).<br>
<br>

Firstly we conducted a systematic review following the PRISMA 2020 method (Page et al., 2021).<br>
<br>

```{r}
#| echo: false
#| out.width: '100%'

include_graphics(here("figures/prisma_flow_diagram.png"))   # Insert the PRISMA Flow Diagram using knitr


```

<br>
We then extracted data from those reports to conduct a meta-analysis.<br>
<br>

```{r Import data}
#| include: false

data <- read_excel(here("data/meta_analysis_data.xlsx"),
                   na = c("", "NA"))   # Import data from the data folder

```

```{r Prep data for analysis}
#| include: false

# Turn the required columns into factors:
data <-
data %>%
  mutate(across(.cols = c(STUDYID,
                          ACCESSION_ID,
                          MULTIPLE_ENDPOINT_CLUSTERID,
                          SHAREDCONTROL_CLUSTERID,
                          TREATMENT,
                          FUNCTIONAL_GROUP,
                          SPECIES_RICHNESS,
                          BEETLES_CONFINED_TO_CAGE,
                          DUNG_TYPE,
                          DUNG_FROZEN_PRIOR_TO_ALIQUOTTING,
                          DUNG_REMOVED_AFTER_BEETLE_ACTIVITY,
                          PLANTS_GERMINATED_BEFORE_DUNG_ADDITION,
                          PLANT_TYPE,
                          CLADE,
                          RESPONSE_AREA,
                          RESPONSE_MEASUREMENT,
                          RESPONSE,
                          CONTROL_TREATMENT,
                          EXPERIMENT_SETTING), 
                as.factor))
sapply(data, class)   # Check that the required columns are now factors

data <-
  data %>%
  mutate(GRAMS_DUNG_PER_CM_SQUARED = DUNG_QUANTITY_IN_GRAMS / SURFACE_AREA_CM_SQUARED,   # Calculate a variable for the grams of dung per cm squared of each plot/mesocosm
         GRAMS_DUNG_PER_BEETLE_NUMBER = DUNG_QUANTITY_IN_GRAMS / NUMBER_OF_BEETLES,   # Calculate a variable for the grams of dung per beetle number
         GRAMS_DUNG_PER_BEETLE_WEIGHT = DUNG_QUANTITY_IN_GRAMS / TOTAL_BEETLE_WEIGHT_IN_MG,)   # Calculate a variable for the grams of dung per beetle weight

```

Our data features correlated, or dependent, outcomes within studies (Noble et al., 2017). This correlation can be due to:<br> 
**Shared control** - Where multiple treatments are compared to the same control (e.g. Manning et al., 2017).<br>
**Shared measurements** - Where more than one outcome/measurement is reported for the same study (e.g. Johnson et al., 2016).<br>
**Within-study temporal correlation** - Where the effect is measured at multiple timepoints (e.g. Nervo et al., 2017).<br>
For more information on non-dependent effect sizes see Nakagawa & Santos (2012), Noble et al. (2017) and Bishop & Nakagawa (2021).<br>
<br>

We deal with the **shared control** aspect of our dataset before calculating the effect sizes.<br>
To do this we modify the control sample size (CONTROL_N) to account for those studies with shared controls.
Next we divide the sample size of each control (CONTROL_N) by the number of shared controls within its study (SHAREDCONTROL_COUNT). 
This creates a SHARED_CONTROL_N value which is then used (in escalc) to calculate the effect size for each outcome.<br>
<br>

We then use measures of plant growth between 'dung+beetles' and 'dung_only' treatments to calculate effect sizes. Effect sizes are calculated using a log transformed ratio of means, or log response ratio (lnRR) (Hedges et al., 1999). This is a usefull measurement as we can determine a percentage increase in plant growth. The metafor package was used to calculate the effect sizes (Viechtbauer 2010). For measure = "ROM", the log is taken of the ratio of means, which makes this outcome measure symmetric around 0 and yields a corresponding sampling distribution that is closer to normality (Viechtbauer 2010).<br> 
<br>

```{r Removing outliers}
#| include: false

#######################################################################################
# Testing the removal of outliers (with large effect_size)        CAN DELETE LATER

# data <-
# data %>%
# filter(ACCESSION_ID != "A576") %>%
# filter(ACCESSION_ID != "A381") %>%
# filter(ACCESSION_ID != "A382")

#######################################################################################

```

```{r Calculate effect sizes}
#| include: false

data1 <- 
data %>% 
# Isolate the dung+beetles treatments with dung_only controls
filter(TREATMENT == "dung+beetles",   # Isolate the "dung+beetles" treatments from the TREATMENT column
       CONTROL_TREATMENT == "dung_only") %>%   # AND isolate the "dung_only+beetles" treatments from the CONTROL_TREATMENT column   
# Filter out the studies that don't have the required measurements to calculate both an effect size and effect size variance
drop_na(TREATMENT_N,
        TREATMENT_MEAN,
        TREATMENT_SD,
        CONTROL_N,
        CONTROL_MEAN,
        CONTROL_SD) %>%   # Remove all studies that have 'NA' recorded for any of the six measurements required to calculate an effect size
group_by(STUDYID) %>%
mutate(SHAREDCONTROL_COUNT = n_distinct(SHAREDCONTROL_CLUSTERID),   # Count the number of unique control groups within each study
       SHARED_CONTROL_N = CONTROL_N / SHAREDCONTROL_COUNT)   # Divide the sample size of each control (CONTROL_N) by the number of shared controls within its study

# Calculate an Effect Size (yi) and corresponding Sampling Variance (vi)
data1 <- escalc(measure="ROM",   # The effect size calculated will be log transformed ratio of means (metafor::escalc)
                m1i=TREATMENT_MEAN,   # m1i = the treatment mean (e.g. dung+beetles or dung_only)
                sd1i=TREATMENT_SD,   # sd1i = the treatment st.dev
                n1i=TREATMENT_N,   # n1i = the treatment sample size
                m2i=CONTROL_MEAN,   # m2i = the control mean (e.g. dung_only or soil_only)    
                sd2i=CONTROL_SD,   # sd2i = the control st.dev  
                n2i=SHARED_CONTROL_N,   # n2i = the control sample size (here we used our modified control sample size)
                data=data1,
                slab=paste(STUDYID, YEAR, sep=", ")) # A warning incorrectly suggests that NANs produced
# Rename the Effect Size (yi) and corresponding Sampling Variance (vi)columns to make them more intuitive to read 
colnames(data1)[which(names(data1) == "yi")] <- "effect_size"   # The Effect Size column is now labelled 'effect_size'
colnames(data1)[which(names(data1) == "vi")] <- "effect_size_variance"   # The Sampling Variance is now labelled 'effect_size_variance'
# Calculate a standard error (sqrt(effect_size_variance)) and a precision value (1/standard error) (Bishop & Nakagawa, 2021)
data1$se <- sqrt(data1$effect_size_variance)
data1$precision <- 1/data1$se

```

Now we look at the effect sizes for any outliers and remove them if need be.<br>
<br>

```{r Remove outlying effect sizes}
#| include: false

# Firstly look for any outlying negative effect sizes
head(sort(data1$effect_size,decreasing=FALSE),n=10)
# One effect size of -1.2792404 (belonging to ACCESSION_ID: A576) looks to be an outlier. When looking back at the study it was in, it appears to be legitimate

# Now look for any outlying positive effect sizes
head(sort(data1$effect_size,decreasing=TRUE),n=10)
# Two effect sizes of 2.2686835 and 1.7676619 (belonging to ACCESSION_IDs: A381 and A382) look to be an outliers. When looking back at the study they were both in (Johnson et al., 2016), they are two measurements of the same treatment, which featured reduced watering and appear to be legitimate

# The outliers appear legitimate so we leave them in the meta-analysis

```

As the data also contain non-independence in the form of **shared measurements** and **within-study temporal correlation** we create a value called MULTIPLE_ENDPOINT_CLUSTERID.
Whenever multiple plant traits were measured from the same plant at the same time, or when a single plant trait was measured from the same plant at different times, those outcomes received the same MULTIPLE_ENDPOINT_CLUSTERID. Sometimes studies had both Shared measurements and Within-study temporal correlation (e.g. Miranda et al., 1998).<br>
<br>

To deal with non-independence we use multi-level meta-analytic models with variance–covariance matrices. We generate variance-covariance matrices based on a clustered variable, which was MULTIPLE_ENDPOINT_CLUSTERID.<br>
<br>

We produce variance-covariance matrices with an assumed to have a correlation of 0.5, but this can be changed to higher or lower values as a sensitivity test. A correlation value (rho) of 0 indicates no correlation and 1 a perfect correlation (Dougherty et al., 2022).<br>
<br>

We expect that when multiple plant traits were measured from the same plant at the same time (e.g. shoot weight and total weight), that the correlation will be high. When looking through the relevant studies, the effect of dung beetles on plant growth appears to vary through time, therefore, we assume when a single plant trait was measured from the same plant at different times that the correlation will be lower. As a compromise we select an rho of 0.5, which is a common assumption in meta-analyses (Dougherty et al., 2022) and the default value in the make_VCV_matrix function.<br>
<br>
**Note: Although I've just outlined why we chose an rho of 0.5, I'm tempted to ditch the rho of 0.5 and use a higher correlation value?  In Bishop & Nakagawa they used an rho of 0.5, but they looked at yield AND various aspects of faba bean pods, which would probably be less-correlated than just looking at different aspects of yield alone. When using a higher correlation value (0.9) the plant growth moderators then appear influential (not saying that in a p-hacking kind of way, but maybe an rho of 0.9 highlights that the plant measurements are genuinely highly correlated and that demonstrates it)**

```{r Assumed correlation within studies}
#| include: false

################# The following line assigns a correlation value for the variance-covariance matrices - it can be changed later as a sensitivity test #################
assumed_variance <- 0.5   # 0 = no correlation and 1 = perfect correlation. 0.5 is standard practice and the default value in make_VCV_matrix

# Construct the variance-covariance matrices
variance.covariance.matrices <- 
  make_VCV_matrix(data = data1,
                  V = "effect_size_variance",
                  cluster = "MULTIPLE_ENDPOINT_CLUSTERID",
                  obs = "ACCESSION_ID",
                  type = "vcv",
                  rho = assumed_variance)
is.positive.definite(variance.covariance.matrices)

```

Now we compare the model with variance-covariance (vcov) matrices to a model without matrices (i.e. comparing a model that assumes non-dependence between effect sizes within studies, to a model that doesn't). We do this by finding the one with the lowest AIC value.<br>
<br>

```{r Compare vcov and null models}
#| include: false

# Again, Arrange data1 by MULTIPLE_ENDPOINT_CLUSTERID (ascending)
data1 <- data1[order(data1$MULTIPLE_ENDPOINT_CLUSTERID), ]

# The RE model contains vcov matrices (it assumes non-dependence between effect sizes within studies)
RE <- rma.mv(yi = effect_size,
             V = variance.covariance.matrices,
             random = list(~1 | STUDYID, 
                           ~1 | ACCESSION_ID), 
             data = data1, 
             method = "ML")
summary(RE)
AIC(RE) #-41.32148

# The null.RE model has no vcov matrices (it assumes dependence between effect sizes within studies)
null.RE <- rma.mv(yi = effect_size,
                  V = effect_size_variance,
                  random = list(~1 | STUDYID,
                                ~1 | ACCESSION_ID),
                  data = data1, 
                  method = "ML")
summary(null.RE)
AIC(null.RE) #-31.26941

# The RE model (that accounts for non-dependence) is a better fit

```

The model with vcov matrices fits best, so we now report the results in the paper using model fitted with restricted maximum likelihood.<br>
Note: The model with vcov matrices is still the best fit with assumed variances of 0.1 and 0.9.<br>
<br>

```{r Multi-level meta-analysis - null model}
#| include: false

# To report the results in our paper we convert method = "ML" to "REML"
RE.reml <- rma.mv(yi = effect_size,
             V = variance.covariance.matrices,
             random = list(~1 | STUDYID, 
                           ~1 | ACCESSION_ID), 
             data = data1, 
             method = "REML")

summary(RE.reml)

```

We then quantify the total variance (heterogeneity) attributable to each of the three levels.<br>
Here $I^{2}$ represents the amount of variation not attributable to sampling error. It is split into two parts; within clusters and between-cluster variation.<br>

```{r Testing the heterogeneity}
#| echo: false

I2_RE.reml <- as.data.frame(i2_ml(RE.reml))
I2_RE.reml

```

$I^{2}_{Level 2}$ (STUDYID) accounts for ~`r round(((I2_RE.reml["I2_STUDYID", 1] / I2_RE.reml["I2_Total", 1]) * 100), digits = 2)`% of heterogeneity and $I^{2}_{Level 3}$ (ACCESSION_ID) accounts for ~`r round(((I2_RE.reml["I2_ACCESSION_ID", 1] / I2_RE.reml["I2_Total", 1]) * 100), digits = 2)`% of heterogeneity. Therefore, this indicates that the majority of variance is attributable to heterogeneity variance within clusters on the second level (STUDYID).<br>
<br>

Now we calculate the **overall estimate of plant growth increase from beetle activity**. This is done by back-transforming the lnRR.<br>
<br>

```{r Overall average estimate of plant growth}
#| include: false

RE.reml.estimate <- exp(RE.reml$b[[1]]) - 1
RE.reml.estimate

```

Overall, in the studies we assessed, beetles increased plant growth by `r round(RE.reml.estimate, digits = 4)*100`% above the 'dung_only' controls.<br>
Note: With an assumed correlation (rho) of 0.1 RE.reml.estimate = 0.133.<br>
Note: With an assumed correlation (rho) of 0.9 RE.reml.estimate = 0.1395.<br>
<br>

Now we calculate the **overall confidence intervals and prediction intervals**. A prediction interval is the range within which the effect size of a new study outcome would likely be, given this new outcome was selected at random from the same population of the studies already included in the meta-analysis (Spineli & Pandis, 2020).<br>
<br>

```{r Confidence and prediction intervals}
#| echo: false

RE.reml.res <- (mod_results(model = RE.reml,
                            mod = "1",
                            group = "STUDYID",
                            data = data1))

# We back-transform the prediction intervals for reporting in the paper.
RE.reml.lowerPR <- exp(RE.reml.res$mod_table$lowerPR) - 1
RE.reml.upperPR <- exp(RE.reml.res$mod_table$upperPR) - 1
# We back-transform the confidence intervals for reporting in the paper.
RE.reml.lowerCL <- exp(RE.reml.res$mod_table$lowerCL) - 1
RE.reml.upperCL <- exp(RE.reml.res$mod_table$upperCL) - 1

```

Overall, we estimate that when dung beetles access dung, plant growth increases by `r round(RE.reml.estimate, digits = 4)*100`% (CI `r round((RE.reml.lowerCL), digits = 2)`%-`r round((RE.reml.upperCL), digits = 2)`%). The prediction intervals (PI `r round((RE.reml.lowerPR), digits = 2)`%-`r round((RE.reml.upperPR), digits = 2)`%) indicate that if we randomly selected a study outcome from those included in this meta-analysis, many would show a negative effect of dung beetles on plant growth.<br>
<br>


# Visualise the results


<br>
We can now make an orchard plot to visualise our results.<br>
<br>
The orchard plot contains confidence intervals (thick horizontal lines) and prediction intervals (thin horizontal lines) around an overall effect size estimate. Each point represents the scaled individual effect size of a study outcome. The position of each point along the x-axis is determined by its effect size. Points along the y-axis are scattered to both reduce overplotting and help visualise point density. See Nakagawa et al. (2021) for more information on orchard plots.<br>
<br>

```{r Orchard plot}
#| echo: false
#| message: false

wes_colours <- wes_palettes$GrandBudapest1 # prepping the colours for later on
figure_orchard <- 
orchard_plot(RE.reml, 
             mod = "1",   # Set to "1" for intercept only model
             group = "STUDYID", 
             data = data1, 
             #k = FALSE,   # Mute the 'k = (number of effect sizes)' label
             xlab = "lnRR (effect size)") +
  scale_fill_manual(values=wes_colours[2]) +
  scale_colour_manual(values=wes_colours[3]) +  
  theme(panel.background = element_rect(fill = "transparent", 
                                        color = NA),   # background of the panel
        plot.background = element_rect(fill = "transparent", 
                                       color = NA),   # background of the plot
        legend.background = element_rect(fill = "transparent"),    # get rid of legend background
        legend.key = element_rect(fill = "transparent", 
                                  colour = NA))    # get rid of legend background
figure_orchard
# The orachaRd package/paper explainer has some good code for modifying orchard plots (https://github.com/daniel1noble/orchaRd) (Nakagawa et al., 2021)
ggsave(filename = (here("figures/orchard_plot.png")),
       plot = figure_orchard,
       bg = "transparent")   # Plot with a transparent background
# If there is a 'Graphics API version mismatch' when using ggsave try re-installing the ragg package

```

We can also make a caterpillar plot.<br>
<br>
The caterpillar plot shows effect sizes for each study outcome along with their confidence intervals.
At the bottom of the plot there is a diamond that represents an overall mean effect size along with confidence intervals (mean in the center and CIs are the horizontal points of the diamond). This diamond lies within the prediction intervals.<br>
See Nakagawa et al. (2021) for more information on caterpillar plots.<br>

```{r Caterpillar plot 1}
#| echo: false
#| message: false 

figure_caterpillar <- 
caterpillars(RE.reml.res, 
             mod = "1", 
             group = "STUDYID", 
             data = data1,
             #k = FALSE,
             xlab = "effect size") +
  theme_classic() +
  scale_fill_manual(values=wes_colours) +
  scale_colour_manual(values=wes_colours) +  
  theme(panel.background = element_rect(fill = "transparent", 
                                        color = NA),
        plot.background = element_rect(fill = "transparent", 
                                       color = NA),
        legend.background = element_rect(fill = "transparent"),
        legend.key = element_rect(fill = "transparent", 
                                  colour = NA))
figure_caterpillar
ggsave(filename = (here("figures/caterpillar_plot.png")),
       plot = figure_caterpillar,
       bg = "transparent")

```

```{r Caterpillar plot 2}
#| include: false
#| message: false


# Here's another caterpillar plot that is more customisable

# Calculate the confidence intervals for each individual study outcome
data1$lowerCI <- data1$effect_size - stats::qnorm(0.975) * sqrt(data1$effect_size_variance)
data1$upperCI <- data1$effect_size + stats::qnorm(0.975) * sqrt(data1$effect_size_variance)

# Data manipulation to enable geom_path() to plot confidence intervals (grouping them by ACCESSION_ID)
data1_long <-   # Subset of data1 with the columns 'data1, ACCESSION_ID, lowerCI, upperCI, effect_size'
  select(data1, ACCESSION_ID, lowerCI, upperCI, effect_size) 
data1_long <- data1_long[order(data1_long$effect_size), ]   # Sort dataset by effect size to make caterpillar plot look proper
data1_long$y_coord <- nrow(data1_long):1   # Create a list of numbers that will later act as y-coordinates in the plot
data1_long <-
  data1_long %>%
  pivot_longer(
    cols = ends_with("CI"),
    names_to = "CI"
  )
figure_caterpillar2 <- 
  ggplot() +
# Insert a vertical line at 0 indicating 'no effect'
  geom_vline(xintercept = 0,   # Set the position along the x-axis for the vertical line 
             colour = "grey",   # Set the line colour
             linetype = "longdash") +   # Make the line dashed
# Insert confidence intervals for each individual study outcome
geom_path(data = data1_long,
                           aes(x = value,   # Set the x-coordinate
                               y = y_coord,   # Set the y-coordinate
                               group = ACCESSION_ID),   # Group the coordinates (as each line on the plot is made from x- and y-coodinates on seperate lines in the dataset)
          colour = "dark grey",   # Set the line colour
          size = 1,   # Set the line size
          lineend = "round") +   # Make the ends of the line round (rather than the default square)
# Insert the effect size for each individual study outcome
geom_point(data = data1_long,
           aes(x = effect_size,   # Set the effect size
               y = y_coord),   # Set the y-coordinate
           col = "black",   # Set the point colour
           size = 1) +   # Set the point size
# Adding plot aesthetics
  theme_classic() +   # Make the plot background blank   
  theme(panel.background = element_rect(fill = "transparent"),   # Make the panel background transparent   
        plot.background = element_rect(fill = "transparent",   # Make the plot background transparent   
                                       color = NA),
        plot.title = element_text(hjust = 0.5),   # Center the title
        axis.text.y=element_blank(),   # Mute the y-axis text
        axis.ticks.y=element_blank(),   # Mute the y-axis ticks
        axis.line.y = element_blank(),   # Mute the y-axis line
        axis.line.x = element_line(colour = "black",   # Customise the the x-axis line
                                   size = 1,
                                   linetype = "solid")) +
  labs(title = "Caterpillar plot",   # Label the plot
       x ="lnRR (effect size)",   # Label the x-axis (using 'expression' and 'paste' to incorporate an italic letter)
       y = NULL)  # Mute the y-axis label
  
# Set how far off the y-axis the diamond will be 
summary_bar_spacer <- -2
id <- "a"   # Create an arbitrary id for the upcoming diamond
x_coordinates <- c(RE.reml.lowerCL,   # Lower confidence interval for the overall study (left point of diamond)
                   RE.reml.estimate,   # Mean effect size for the overall study (horizontal mid-point of diamond) 
                   RE.reml.upperCL,   # Upper confidence interval for the overall study (right point of diamond)
                   RE.reml.estimate)   # Mean effect size for the overall study (horizontal mid-point of diamond)  
y_coordinates <- c(summary_bar_spacer,   # Vertical mid-point of the diamond (equal to summary_bar_spacer)
                   summary_bar_spacer+2,   # Top point of the diamond (equal to summary_bar_spacer + 2) 
                   summary_bar_spacer,   # Vertical mid-point of the diamond (equal to summary_bar_spacer)
                   summary_bar_spacer-2)   # Bottom point of the diamond (equal to summary_bar_spacer - 2) 
plot.diamond <- data.frame(id, x_coordinates, y_coordinates)   # Make a dataframe of the diamond coordinates
# Now add in the diamond and prediction intervals (it will be underneath the diamond)
figure_caterpillar2 <- figure_caterpillar2 +
  # Add the overall prediction intervals to the plot
  geom_linerange(data = plot.diamond,
                 aes(x = RE.reml.estimate,
                     y = summary_bar_spacer,
                     #y = 1,
                     xmax = RE.reml.upperPR,   # The lower prediction interval
                     xmin = RE.reml.lowerPR),   # The upper prediction interval
                 col = "grey",
                 size = 1) +
  
# Add the diamond to the caterpillar plot (it mill now be on top of the line for the overall prediction intervals)
    geom_polygon(data = plot.diamond,   # Using the dataframe with the diamond coordinates
               aes(fill = id,   # Fill diamond according to the (arbitrary) id (this is kind of meaningless when creating a single shape)
                   group = id,   # Group coordinates according to the (arbitrary) id (this is kind of meaningless when creating a single shape)
                   x = x_coordinates,   # Plot x-coordinates
                   y = y_coordinates),   # Plot y-coordinates
               fill = "black",   # Colour the centre of the diamond
               col = "black")   # Colour the edge of the diamond
figure_caterpillar2
ggsave(filename = (here("figures/caterpillar_plot2.png")),
       plot = figure_caterpillar2,
       bg = "transparent")

```


# Investigating moderators


Next we test to see if moderators improve the model fit.<br> 
We couldn't fully test interactions between moderators due to missing combinations of levels, so we tested them individually. We start by investigating the ecological moderators.<br>


## Plant response
This moderator refers to the type of plant measurement used (either shoot height, root height, total height, shoot weight, root weight or total weight).<br>

**Note: There is a warning message: Redundant predictors dropped from the model**

```{r RESPONSE moderator}
#| include: false

# Our original/null model (maximum likelihood (RE), not restricted maximum likelihood (RE.reml))
summary(RE)

# Our model testing for RESPONSE as a moderator
RE.RESPONSE.ml <- rma.mv(yi = effect_size,
                         V = variance.covariance.matrices,
                         mods = ~RESPONSE - 1,
                         random = list(~1 | STUDYID,
                                       ~1 | ACCESSION_ID),
                         data = data1,
                         method = "ML")

anova(RE.RESPONSE.ml, RE)   # Full is with moderator, Reduced is without (null)

# Re-fit the model with REML for reporting estimates in the paper
RE.RESPONSE.reml <- rma.mv(yi = effect_size,
                           V = variance.covariance.matrices,
                           mods = ~RESPONSE - 1,
                           random = list(~1 | STUDYID,
                                         ~1 | ACCESSION_ID),
                           data = data1,
                           method = "REML")

```

```{r Results RESPONSE moderator}
#| include: false

summary(RE.RESPONSE.reml)

RE.RESPONSE.reml.res <- mod_results(RE.RESPONSE.reml,
                                     group = "STUDYID",
                                     data = data1,
                                     mod = "RESPONSE")

RESPONSE.plot <- 
  orchard_plot(RE.RESPONSE.reml.res,
               mod = "1",
               group = "STUDYID",
               data = data.FG,
               xlab ="lnRR (effect size)") +
  labs(title = "Plant measurement type influencing effect size",
       x = "Plant measurement") +
  scale_x_discrete(labels=c("Shoot_height" = "Shoot\nheight", 
                            "Root_height" = "Root\nheight",
                            "Total_height" = "Total\nheight",
                            "Shoot_weight" = "Shoot\nweight",
                            "Root_weight" = "Root\nweight",
                            "Total_weight" = "Total\nweight"))
RESPONSE.plot

```

**Plant response is slightly influential to the overall estimate** (LRT RE.RESPONSE.ml vs RE, *p*=`r round((anova(RE.RESPONSE.ml, RE)$pval), digits = 3)`).<br>
Response is slightly influential with assumed correlations (rho) of 0.1 (LRT RE.RESPONSE.ml vs RE, *p*=0.0725) and 0.9 (LRT RE.RESPONSE.ml vs RE, *p*=0.0629).<br>
<br>

Shoot weight was the dominant plant response assessed in the studies. Other plant responses appear influential but have small sample sizes, so we group all the non-Shoot weight measurements together to create one group (with a larger collective sample size) and see if that is still influential.<br>
<br>

```{r RESPONSE2 moderator}
#| include: false

# Create a new RESPONSE category. The RESPONSE2 measured is either shoot weight or other
data1<-data1 %>%
mutate(RESPONSE2 = if_else(RESPONSE == "shoot_weight", "shoot_weight", "other"))

# Our original/null model (maximum likelihood (RE), not restricted maximum likelihood (RE.reml))
summary(RE)

# Our model testing for RESPONSE2 as a moderator
RE.RESPONSE2.ml <- rma.mv(yi = effect_size,
                         V = variance.covariance.matrices,
                         mods = ~RESPONSE2 - 1,
                         random = list(~1 | STUDYID,
                                       ~1 | ACCESSION_ID),
                         data = data1,
                         method = "ML")

anova(RE.RESPONSE2.ml, RE)   # Full is with moderator, Reduced is without (null)

# Re-fit the model with REML for reporting estimates in the paper
RE.RESPONSE2.reml <- rma.mv(yi = effect_size,
                           V = variance.covariance.matrices,
                           mods = ~RESPONSE2 - 1,
                           random = list(~1 | STUDYID,
                                         ~1 | ACCESSION_ID),
                           data = data1,
                           method = "REML")

```

```{r Results RESPONSE2 moderator}
#| include: false

summary(RE.RESPONSE2.reml)

RE.RESPONSE2.reml.res <- mod_results(RE.RESPONSE2.reml,
                                     group = "STUDYID",
                                     data = data1,
                                     mod = "RESPONSE2")

RESPONSE2.plot <- 
  orchard_plot(RE.RESPONSE2.reml.res,
               mod = "1",
               group = "STUDYID",
               data = data.FG,
               xlab ="lnRR (effect size)") +
  labs(title = "Plant measurement type influencing effect size",
       x = "Plant measurement") +
  scale_x_discrete(labels=c("Shoot_weight" = "Shoot weight", 
                            "other" = "Other"))
RESPONSE2.plot

```

**The grouped plant response is not influential to the overall estimate** (LRT RE.RESPONSE2.ml vs RE, *p*=`r round((anova(RE.RESPONSE2.ml, RE)$pval), digits = 3)`).<br>


## Plant response area
This moderator refers to what section of the plant was measured (shoot, root or total), regardless of whether plant height or weight was measured.<br>

```{r RESPONSE_AREA moderator}
#| include: false
#| warning: false

# Our original/null model (maximum likelihood (RE), not restricted maximum likelihood (RE.reml))
summary(RE)

# Our model testing for RESPONSE_AREA as a moderator
RE.RESPONSE_AREA.ml <- rma.mv(yi = effect_size,
                              V = variance.covariance.matrices,
                              mods = ~RESPONSE_AREA - 1,
                              random = list(~1 | STUDYID,
                                            ~1 | ACCESSION_ID),
                              data = data1,
                              method = "ML")

anova(RE.RESPONSE_AREA.ml, RE)   # Full is with moderator, Reduced is without (null)

```

```{r Results RESPONSE_AREA moderator}
#| include: false

# Re-fit the model with REML for reporting estimates in the paper
RE.RESPONSE_AREA.reml <- rma.mv(yi = effect_size,
                                V = variance.covariance.matrices,
                                mods = ~RESPONSE_AREA - 1,
                                random = list(~1 | STUDYID,
                                              ~1 | ACCESSION_ID),
                                data = data1,
                                method = "REML")
summary(RE.RESPONSE_AREA.reml)

```

**Plant response area is not influential to the overall estimate** (LRT RE.RESPONSE_AREA.ml vs RE, *p*=`r round((anova(RE.RESPONSE_AREA.ml, RE)$pval), digits = 3)`).<br>
<br>


## Plant response measurment type
This moderator refers to whether plant height or weight was measured, regardless of what section of the plant was measured.<br>

```{r RESPONSE_MEASUREMENT moderator}
#| include: false
#| warning: false

# Our original/null model (maximum likelihood (RE), not restricted maximum likelihood (RE.reml))
summary(RE)

# Our model testing for RESPONSE_MEASUREMENT as a moderator
RE.RESPONSE_MEASUREMENT.ml <- rma.mv(yi = effect_size,
                              V = variance.covariance.matrices,
                              mods = ~RESPONSE_MEASUREMENT - 1,
                              random = list(~1 | STUDYID,
                                            ~1 | ACCESSION_ID),
                              data = data1,
                              method = "ML")

anova(RE.RESPONSE_MEASUREMENT.ml, RE)   # Full is with moderator, Reduced is without (null)

```

```{r Results RESPONSE_MEASUREMENT moderator}
#| include: false

# Re-fit the model with REML for reporting estimates in the paper
RE.RESPONSE_MEASUREMENT.reml <- rma.mv(yi = effect_size,
                                V = variance.covariance.matrices,
                                mods = ~RESPONSE_MEASUREMENT - 1,
                                random = list(~1 | STUDYID,
                                              ~1 | ACCESSION_ID),
                                data = data1,
                                method = "REML")
summary(RE.RESPONSE_MEASUREMENT.reml)

```

**Plant response measurment type is not influential to the overall estimate** (LRT RE.RESPONSE_MEASUREMENT.ml vs RE, *p*=`r round((anova(RE.RESPONSE_MEASUREMENT.ml, RE)$pval), digits = 3)`).<br>
<br>


## Beetle functional group
Some studies have unknown functional groups so we filter out those study outcomes with NAs listed for FUNCTIONAL_GROUP.<br>

```{r FUNCTIONAL_GROUP moderator}
#| echo: false
#| include: false

data.FG <- 
  data %>% 
  # Isolate the dung+beetles treatments with dung_only controls
  filter(TREATMENT == "dung+beetles",   # Isolate the "dung+beetles" treatments from the TREATMENT column
         CONTROL_TREATMENT == "dung_only") %>%    # AND isolate the "dung_only+beetles" treatments from the CONTROL_TREATMENT column   
  drop_na(FUNCTIONAL_GROUP) %>%   # And filter out the studies with NAs listed for the FUNCTIONAL_GROUP

  #filter(STUDYID != "Barragán et al.") %>%   ############## Remove the Barragán et al., 2022 study with all the roller beetles ##############

  # Filter out the studies that don't have the required measurements to calculate an effect size
  drop_na(TREATMENT_N,
          TREATMENT_MEAN,
          TREATMENT_SD,
          CONTROL_N,
          CONTROL_MEAN,
          CONTROL_SD) %>%   # Remove all studies that have 'NA' recorded for any of the six measurements required to calculate an effect size
  group_by(STUDYID) %>%
  mutate(SHAREDCONTROL_COUNT = n_distinct(SHAREDCONTROL_CLUSTERID),   # Count the number of unique control groups within each study
         SHARED_CONTROL_N = CONTROL_N / SHAREDCONTROL_COUNT)   # Divide the sample size of each control (CONTROL_N) by the number of shared controls within its study

# Calculate an Effect Size (yi) and corresponding Sampling Variance (vi)
data.FG <- escalc(measure="ROM",   # The effect size calculated will be log transformed ratio of means (metafor::escalc)
                   m1i=TREATMENT_MEAN,   # m1i = the treatment mean (e.g. dung+beetles or dung_only)
                   sd1i=TREATMENT_SD,   # sd1i = the treatment st.dev
                   n1i=TREATMENT_N,   # n1i = the treatment sample size
                   m2i=CONTROL_MEAN,   # m2i = the control mean (e.g. dung_only or soil_only)    
                   sd2i=CONTROL_SD,   # sd2i = the control st.dev  
                   n2i=SHARED_CONTROL_N,   # n2i = the control sample size (here we used our modified control sample size)
                   data=data.FG,
                   slab=paste(STUDYID, YEAR, sep=", ")) # A warning incorrectly suggests that NANs produced
# Rename the Effect Size (yi) and corresponding Sampling Variance (vi)columns to make them more intuitive to read 
colnames(data.FG)[which(names(data.FG) == "yi")] <- "effect_size"   # The Effect Size column is now labelled 'effect_size'
colnames(data.FG)[which(names(data.FG) == "vi")] <- "effect_size_variance"   # The Sampling Variance is now labelled 'effect_size_variance'
# Calculate a standard error (sqrt(effect_size_variance)) and a precision value (1/standard error) (Bishop & Nakagawa, 2021)
data.FG$se <- sqrt(data.FG$effect_size_variance)
data.FG$precision <- 1/data.FG$se
# Make vcov matrices
variance.covariance.matrices.FG <- 
  make_VCV_matrix(data = data.FG,
                  V = "effect_size_variance",
                  cluster = "MULTIPLE_ENDPOINT_CLUSTERID",
                  obs = "ACCESSION_ID",
                  type = "vcv",
                  rho = assumed_variance)   # Setting the assumed correlation value at 0.5
is.positive.definite(variance.covariance.matrices.FG)

# Again, Arrange data.FG by MULTIPLE_ENDPOINT_CLUSTERID (ascending)
data.FG <- data.FG[order(data.FG$MULTIPLE_ENDPOINT_CLUSTERID), ]

# The RE.FG model contains vcov matrices (it assumes non-dependence between effect sizes within studies)
RE.FG <- rma.mv(yi = effect_size,
                 V = variance.covariance.matrices.FG,
                 random = list(~1 | STUDYID,
                               ~1 | ACCESSION_ID), 
                 data = data.FG, 
                 method = "ML")
summary(RE.FG)
AIC(RE.FG) #-19.52569

# Our model testing for FUNCTIONAL_GROUP as a moderator
RE.FG.ml <- rma.mv(yi = effect_size,
                    V = variance.covariance.matrices.FG,
                    mods = ~FUNCTIONAL_GROUP - 1,
                    random = list(~1 | STUDYID,
                                  ~1 | ACCESSION_ID),
                    data = data.FG,
                    method = "ML")
summary(RE.FG.ml)
AIC(RE.FG.ml) #-21.87142
anova(RE.FG.ml, RE.FG)   # Full is with moderator, Reduced is without (null)

```

```{r Results FUNCTIONAL_GROUP moderator}
#| echo: false

# Re-fit the model with REML for reporting estimates in the paper
RE.FG.reml <- rma.mv(yi = effect_size,
                      V = variance.covariance.matrices.FG,
                      mods = ~FUNCTIONAL_GROUP - 1,
                      random = list(~1 | STUDYID,
                                    ~1 | ACCESSION_ID), 
                      data = data.FG,
                      method = "REML")
summary(RE.FG.reml)
RE.FG.reml.res <- (mod_results(RE.FG.reml,
                           group = "STUDYID",
                           data = data.FG,
                           mod = "FUNCTIONAL_GROUP"))

FUNCTIONAL_GROUP.plot <- 
  orchard_plot(RE.FG.reml.res,
               mod = "1",
               group = "STUDYID",
               data = data.FG,
               xlab ="lnRR (effect size)") +
  labs(title = "Beetle funtional group influencing plant growth",
       x = "Funtional group")
FUNCTIONAL_GROUP.plot

```

**Beetle functional group is influential to the overall estimate** (LRT RE.FG.ml vs RE.FG, *p*=`r round((anova(RE.FG.ml, RE.FG)$pval), digits = 3)`).<br>

When looking at the Roller functional group, all 18 outcomes come from a single study, Barragán et al. (2022). After removing the Barragán et al. (2022) study, beetle functional group is still influential to the overall estimate, although less influential.<br>
<br>


## Species richness
Some studies have unknown species richness so we filter out those study outcomes with NAs listed for SPECIES_RICHNESS.<br>

**Note: There is a warning message: Redundant predictors dropped from the model**

```{r SPECIES_RICHNESS moderator}
#| echo: false
#| include: false

data.SR <- 
  data %>% 
  # Isolate the dung+beetles treatments with dung_only controls
  filter(TREATMENT == "dung+beetles",   # Isolate the "dung+beetles" treatments from the TREATMENT column
         CONTROL_TREATMENT == "dung_only") %>%    # AND isolate the "dung_only+beetles" treatments from the CONTROL_TREATMENT column   
  drop_na(SPECIES_RICHNESS) %>%   # And filter out the studies with NAs listed for the SPECIES_RICHNESS
# Filter out the studies that don't have the required measurements to calculate an effect size
drop_na(TREATMENT_N,
        TREATMENT_MEAN,
        TREATMENT_SD,
        CONTROL_N,
        CONTROL_MEAN,
        CONTROL_SD) %>%   # Remove all studies that have 'NA' recorded for any of the six measurements required to calculate an effect size
  group_by(STUDYID) %>%
  mutate(SHAREDCONTROL_COUNT = n_distinct(SHAREDCONTROL_CLUSTERID),   # Count the number of unique control groups within each study
         SHARED_CONTROL_N = CONTROL_N / SHAREDCONTROL_COUNT)   # Divide the sample size of each control (CONTROL_N) by the number of shared controls within its study

data.SR <-
  data.SR %>%
  mutate(as.factor(SPECIES_RICHNESS))


# Calculate an Effect Size (yi) and corresponding Sampling Variance (vi)
data.SR <- escalc(measure="ROM",   # The effect size calculated will be log transformed ratio of means (metafor::escalc)
                   m1i=TREATMENT_MEAN,   # m1i = the treatment mean (e.g. dung+beetles or dung_only)
                   sd1i=TREATMENT_SD,   # sd1i = the treatment st.dev
                   n1i=TREATMENT_N,   # n1i = the treatment sample size
                   m2i=CONTROL_MEAN,   # m2i = the control mean (e.g. dung_only or soil_only)    
                   sd2i=CONTROL_SD,   # sd2i = the control st.dev  
                   n2i=SHARED_CONTROL_N,   # n2i = the control sample size (here we used our modified control sample size)
                   data=data.SR,
                   slab=paste(STUDYID, YEAR, sep=", ")) # A warning incorrectly suggests that NANs produced
# Rename the Effect Size (yi) and corresponding Sampling Variance (vi)columns to make them more intuitive to read 
colnames(data.SR)[which(names(data.SR) == "yi")] <- "effect_size"   # The Effect Size column is now labelled 'effect_size'
colnames(data.SR)[which(names(data.SR) == "vi")] <- "effect_size_variance"   # The Sampling Variance is now labelled 'effect_size_variance'
# Calculate a standard error (sqrt(effect_size_variance)) and a precision value (1/standard error) (Bishop & Nakagawa, 2021)
data.SR$se <- sqrt(data.SR$effect_size_variance)
data.SR$precision <- 1/data.SR$se
# Make vcov matrices
variance.covariance.matrices.SR <- 
  make_VCV_matrix(data = data.SR,
                  V = "effect_size_variance",
                  cluster = "MULTIPLE_ENDPOINT_CLUSTERID",
                  obs = "ACCESSION_ID",
                  type = "vcv",
                  rho = assumed_variance)   # Setting the assumed correlation value at 0.5
is.positive.definite(variance.covariance.matrices.SR)

# Again, Arrange data.SR by MULTIPLE_ENDPOINT_CLUSTERID (ascending)
data.SR <- data.SR[order(data.SR$MULTIPLE_ENDPOINT_CLUSTERID), ]

# The RE.SR model contains vcov matrices (it assumes non-dependence between effect sizes within studies)
RE.SR <- rma.mv(yi = effect_size,
                 V = variance.covariance.matrices.SR,
                 random = list(~1 | STUDYID, 
                               ~1 | ACCESSION_ID), 
                 data = data.SR, 
                 method = "ML")
summary(RE.SR)
AIC(RE.SR) #-43.69865

# Our model testing for SPECIES_RICHNESS as a moderator
RE.SR.ml <- rma.mv(yi = effect_size,
                    V = variance.covariance.matrices.SR,
                    mods = ~SPECIES_RICHNESS - 1,
                    random = list(~1 | STUDYID,
                                  ~1 | ACCESSION_ID),
                    data = data.SR,
                    method = "ML")
summary(RE.SR.ml)
AIC(RE.SR.ml) #-40.34772
anova(RE.SR.ml, RE.SR)   # Full is with moderator, Reduced is without (null)

```

```{r Results SPECIES_RICHNESS moderator}
#| include: false

# Re-fit the model with REML for reporting estimates in the paper
RE.SR.reml <- rma.mv(yi = effect_size,
                      V = variance.covariance.matrices.SR,
                      mods = ~SPECIES_RICHNESS - 1,
                      random = list(~1 | STUDYID,
                                    ~1 | ACCESSION_ID),
                      data = data.SR,
                      method = "REML")
summary(RE.SR.reml)

```

**Species richness is not influential to the overall estimate** (LRT RE.SR.ml vs RE.SR, *p*= `r round((anova(RE.SR.ml, RE.SR)$pval), digits = 3)`).<br>
<br>


## Number of beetles
Some studies have an unknown number of beetles so we filter out those study outcomes with NAs listed for NUMBER_OF_BEETLES.<br>

```{r NUMBER_OF_BEETLES moderator}
#| include: false
#| warning: false

data.NOB <- 
  data %>% 
  # Isolate the dung+beetles treatments with dung_only controls
  filter(TREATMENT == "dung+beetles",   # Isolate the "dung+beetles" treatments from the TREATMENT column
         CONTROL_TREATMENT == "dung_only") %>%    # AND isolate the "dung_only+beetles" treatments from the CONTROL_TREATMENT column   
  drop_na(NUMBER_OF_BEETLES) %>%   # And filter out the studies with NAs listed for the NUMBER_OF_BEETLES
# Filter out the studies that don't have the required measurements to calculate an effect size
drop_na(TREATMENT_N,
        TREATMENT_MEAN,
        TREATMENT_SD,
        CONTROL_N,
        CONTROL_MEAN,
        CONTROL_SD) %>%   # Remove all studies that have 'NA' recorded for any of the six measurements required to calculate an effect size
  group_by(STUDYID) %>%
  mutate(SHAREDCONTROL_COUNT = n_distinct(SHAREDCONTROL_CLUSTERID),   # Count the number of unique control groups within each study
         SHARED_CONTROL_N = CONTROL_N / SHAREDCONTROL_COUNT)   # Divide the sample size of each control (CONTROL_N) by the number of shared controls within its study

data.NOB <-
  data.NOB %>%
  mutate(as.integer(NUMBER_OF_BEETLES))

# Calculate an Effect Size (yi) and corresponding Sampling Variance (vi)
data.NOB <- escalc(measure="ROM",   # The effect size calculated will be log transformed ratio of means (metafor::escalc)
                  m1i=TREATMENT_MEAN,   # m1i = the treatment mean (e.g. dung+beetles or dung_only)
                  sd1i=TREATMENT_SD,   # sd1i = the treatment st.dev
                  n1i=TREATMENT_N,   # n1i = the treatment sample size
                  m2i=CONTROL_MEAN,   # m2i = the control mean (e.g. dung_only or soil_only)    
                  sd2i=CONTROL_SD,   # sd2i = the control st.dev  
                  n2i=SHARED_CONTROL_N,   # n2i = the control sample size (here we used our modified control sample size)
                  data=data.NOB,
                  slab=paste(STUDYID, YEAR, sep=", ")) # A warning incorrectly suggests that NANs produced
# Rename the Effect Size (yi) and corresponding Sampling Variance (vi)columns to make them more intuitive to read 
colnames(data.NOB)[which(names(data.NOB) == "yi")] <- "effect_size"   # The Effect Size column is now labelled 'effect_size'
colnames(data.NOB)[which(names(data.NOB) == "vi")] <- "effect_size_variance"   # The Sampling Variance is now labelled 'effect_size_variance'
# Calculate a standard error (sqrt(effect_size_variance)) and a precision value (1/standard error) (Bishop & Nakagawa, 2021)
data.NOB$se <- sqrt(data.NOB$effect_size_variance)
data.NOB$precision <- 1/data.NOB$se
# Make vcov matrices
variance.covariance.matrices.NOB <- 
  make_VCV_matrix(data = data.NOB,
                  V = "effect_size_variance",
                  cluster = "MULTIPLE_ENDPOINT_CLUSTERID",
                  obs = "ACCESSION_ID",
                  type = "vcv",
                  rho = assumed_variance)   # Setting the assumed correlation value at 0.5
is.positive.definite(variance.covariance.matrices.NOB)

# Again, Arrange data.NOB by MULTIPLE_ENDPOINT_CLUSTERID (ascending)
data.NOB <- data.NOB[order(data.NOB$MULTIPLE_ENDPOINT_CLUSTERID), ]

# The RE.NOB model contains vcov matrices (it assumes non-dependence between effect sizes within studies)
RE.NOB <- rma.mv(yi = effect_size,
                   V = variance.covariance.matrices.NOB,
                   random = list(~1 | STUDYID, 
                                 ~1 | ACCESSION_ID), 
                   data = data.NOB, 
                   method = "ML")
summary(RE.NOB)
AIC(RE.NOB) #-37.43324

# Our model testing for NUMBER_OF_BEETLES as a moderator
RE.NOB.ml <- rma.mv(yi = effect_size,
                      V = variance.covariance.matrices.NOB,
                      mods = ~NUMBER_OF_BEETLES,
                      random = list(~1 | STUDYID,
                                    ~1 | ACCESSION_ID),
                      data = data.NOB,
                      method = "ML")
summary(RE.NOB.ml)
AIC(RE.NOB.ml) #-35.44783
anova(RE.NOB.ml, RE.NOB)   # Full is with moderator, Reduced is without (null)

```

```{r Results NUMBER_OF_BEETLES moderator}
#| include: false

# Re-fit the model with REML for reporting estimates in the paper
RE.NOB.reml <- rma.mv(yi = effect_size,
                        V = variance.covariance.matrices.NOB,
                        mods = ~NUMBER_OF_BEETLES,
                        random = list(~1 | STUDYID,
                                      ~1 | ACCESSION_ID),
                        data = data.NOB,
                        method = "REML")
summary(RE.NOB.reml)

```

**The number of beetles (abundance) is not influential to the overall estimate** (LRT RE.NOB.ml vs RE.NOB, *p*= `r round((anova(RE.NOB.ml, RE.NOB)$pval), digits = 3)`).<br>
<br>


## Total beetle weight
Some studies have an unknown total beetle weight so we filter out those study outcomes with NAs listed for TOTAL_BEETLE_WEIGHT_IN_MG.<br>
We initially assessed this moderator and there was nearly a significant influence of (LRT: 3.1688, *p*=0.0751), but after removing two outliers from Badenhorst et al., 2018 there was no significant influence (LRT: 1.0456, *p*=0.3065). Therefore, we conclude that total beetle weight is not influential to the overall estimate.<br>
The two outliers from Badenhorst et al. (2018) can be included in the code chunk below by placing a # before the filter function.<br>

```{r TOTAL_BEETLE_WEIGHT_IN_MG moderator}
#| include: false
#| warning: false

data.TBW <- 
  data %>% 
  # Isolate the dung+beetles treatments with dung_only controls
  filter(TREATMENT == "dung+beetles",   # Isolate the "dung+beetles" treatments from the TREATMENT column
         CONTROL_TREATMENT == "dung_only") %>%    # AND isolate the "dung_only+beetles" treatments from the CONTROL_TREATMENT column   
  drop_na(TOTAL_BEETLE_WEIGHT_IN_MG) %>%   # And filter out the studies with NAs listed for the TOTAL_BEETLE_WEIGHT_IN_MG

  filter(TOTAL_BEETLE_WEIGHT_IN_MG <= 2000) %>%   ############## Remove the two outliers from Badenhorst et al., 2018 ##############

  # Filter out the studies that don't have the required measurements to calculate an effect size
  drop_na(TREATMENT_N,
        TREATMENT_MEAN,
        TREATMENT_SD,
        CONTROL_N,
        CONTROL_MEAN,
        CONTROL_SD) %>%   # Remove all studies that have 'NA' recorded for any of the six measurements required to calculate an effect size
  group_by(STUDYID) %>%
  mutate(SHAREDCONTROL_COUNT = n_distinct(SHAREDCONTROL_CLUSTERID),   # Count the number of unique control groups within each study
         SHARED_CONTROL_N = CONTROL_N / SHAREDCONTROL_COUNT)   # Divide the sample size of each control (CONTROL_N) by the number of shared controls within its study

# Calculate an Effect Size (yi) and corresponding Sampling Variance (vi)
data.TBW <- escalc(measure="ROM",   # The effect size calculated will be log transformed ratio of means (metafor::escalc)
                     m1i=TREATMENT_MEAN,   # m1i = the treatment mean (e.g. dung+beetles or dung_only)
                     sd1i=TREATMENT_SD,   # sd1i = the treatment st.dev
                     n1i=TREATMENT_N,   # n1i = the treatment sample size
                     m2i=CONTROL_MEAN,   # m2i = the control mean (e.g. dung_only or soil_only)    
                     sd2i=CONTROL_SD,   # sd2i = the control st.dev  
                     n2i=SHARED_CONTROL_N,   # n2i = the control sample size (here we used our modified control sample size)
                     data=data.TBW,
                     slab=paste(STUDYID, YEAR, sep=", ")) # A warning incorrectly suggests that NANs produced
# Rename the Effect Size (yi) and corresponding Sampling Variance (vi)columns to make them more intuitive to read 
colnames(data.TBW)[which(names(data.TBW) == "yi")] <- "effect_size"   # The Effect Size column is now labelled 'effect_size'
colnames(data.TBW)[which(names(data.TBW) == "vi")] <- "effect_size_variance"   # The Sampling Variance is now labelled 'effect_size_variance'
# Calculate a standard error (sqrt(effect_size_variance)) and a precision value (1/standard error) (Bishop & Nakagawa, 2021)
data.TBW$se <- sqrt(data.TBW$effect_size_variance)
data.TBW$precision <- 1/data.TBW$se
# Make vcov matrices
variance.covariance.matrices.TBW <- 
  make_VCV_matrix(data = data.TBW,
                  V = "effect_size_variance",
                  cluster = "MULTIPLE_ENDPOINT_CLUSTERID",
                  obs = "ACCESSION_ID",
                  type = "vcv",
                  rho = assumed_variance)   # Setting the assumed correlation value at 0.5
is.positive.definite(variance.covariance.matrices.TBW)

# Again, Arrange data.TBW by MULTIPLE_ENDPOINT_CLUSTERID (ascending)
data.TBW <- data.TBW[order(data.TBW$MULTIPLE_ENDPOINT_CLUSTERID), ]

# The RE.TBW model contains vcov matrices (it assumes non-dependence between effect sizes within studies)
RE.TBW <- rma.mv(yi = effect_size,
                   V = variance.covariance.matrices.TBW,
                   random = list(~1 | STUDYID, 
                                 ~1 | ACCESSION_ID), 
                   data = data.TBW, 
                   method = "ML")
summary(RE.TBW)
AIC(RE.TBW) #-4.263502

# Our model testing for TOTAL_BEETLE_WEIGHT_IN_MG as a moderator
RE.TBW.ml <- rma.mv(yi = effect_size,
                      V = variance.covariance.matrices.TBW,
                      mods = ~TOTAL_BEETLE_WEIGHT_IN_MG,
                      random = list(~1 | STUDYID,
                                    ~1 | ACCESSION_ID),
                      data = data.TBW,
                      method = "ML")
summary(RE.TBW.ml)
AIC(RE.TBW.ml) #-3.309068
anova(RE.TBW.ml, RE.TBW)   # Full is with moderator, Reduced is without (null)

```

```{r Results TOTAL_BEETLE_WEIGHT_IN_MG moderator}
#| include: false
#| message: false

# Re-fit the model with REML for reporting estimates in the paper
RE.TBW.reml <- rma.mv(yi = effect_size,
                      V = variance.covariance.matrices.TBW,
                      mods = ~TOTAL_BEETLE_WEIGHT_IN_MG,
                      random = list(~1 | STUDYID,
                                    ~1 | ACCESSION_ID), 
                      data = data.TBW,
                      method = "REML")
summary(RE.TBW.reml)

# visualise results
pred_time <- predict.rma(RE.TBW.ml)
predict.rma(RE.TBW.ml,
            newmods = c(min(data.TBW$TOTAL_BEETLE_WEIGHT_IN_MG),
                        max(data.TBW$TOTAL_BEETLE_WEIGHT_IN_MG)))
  data.TBW %>%
  mutate(ymin = pred_time$ci.lb,
         ymax = pred_time$ci.ub,
         ymin2 = pred_time$cr.lb,
         ymax2 = pred_time$cr.ub,
         pred = pred_time$pred) %>%
  ggplot(aes(x = TOTAL_BEETLE_WEIGHT_IN_MG,
             y = effect_size, size = sqrt(1/effect_size_variance))) +
  geom_point(shape = 21,
             fill = "grey90") + # geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = ’#0072B2’) + # not quite sure why this does not work
  geom_smooth(aes(y = ymin2),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#0072B2") +
  geom_smooth(aes(y = ymax2),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#0072B2") +
  geom_smooth(aes(y = ymin),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#D55E00") +
  geom_smooth(aes(y = ymax),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#D55E00") +
  geom_smooth(aes(y = pred),
              method = "loess",
              se = FALSE,
              lty = "dashed",
              lwd = 1,
              colour = "black") +
  labs(title = "Total beetle weight influencing plant growth",
       x = "Total beetle weight (mg)",
       y = "lnRR (effect size)",
       size = "Precision (1/SE)") + 
  guides(fill = "none",
         colour = "none") +
  theme_bw()+  
  theme(panel.background = element_rect(fill = "transparent", 
                                        color = NA),
        plot.background = element_rect(fill = "transparent", 
                                       color = NA),
        legend.background = element_rect(fill = "transparent"),
        legend.key = element_rect(fill = "transparent", 
                                  colour = NA))

```

**The total weight of beetles is influential to the overall estimate** (LRT RE.TBW.ml vs RE.TBW, *p*=0.0758)**, but not when outliers are removed** (LRT RE.TBW.ml vs RE.TBW, *p*=`r round((anova(RE.TBW.ml, RE.TBW)$pval), digits = 3)`).<br>
With an assumed variance (rho) of 0.9 (LRT RE.TBW.ml vs RE.TBW, *p*=0.2374).<br>
<br>


## Dung quantity
Some studies have an unknown dung quantity so we filter out those study outcomes with NAs listed for DUNG_QUANTITY_IN_GRAMS.<br>

```{r DUNG_QUANTITY_IN_GRAMS moderator}
#| include: false
#| warning: false

data.DQ <- 
  data %>% 
  # Isolate the dung+beetles treatments with dung_only controls
  filter(TREATMENT == "dung+beetles",   # Isolate the "dung+beetles" treatments from the TREATMENT column
         CONTROL_TREATMENT == "dung_only") %>%    # AND isolate the "dung_only+beetles" treatments from the CONTROL_TREATMENT column   
  drop_na(DUNG_QUANTITY_IN_GRAMS) %>%   # And filter out the studies with NAs listed for the DUNG_QUANTITY_IN_GRAMS

  #filter(DUNG_QUANTITY_IN_GRAMS <= 3000) %>%   ############## Remove the two outliers from Badenhorst et al., 2018 ##############  
  
# Filter out the studies that don't have the required measurements to calculate an effect size
drop_na(TREATMENT_N,
        TREATMENT_MEAN,
        TREATMENT_SD,
        CONTROL_N,
        CONTROL_MEAN,
        CONTROL_SD) %>%   # Remove all studies that have 'NA' recorded for any of the six measurements required to calculate an effect size
  group_by(STUDYID) %>%
  mutate(SHAREDCONTROL_COUNT = n_distinct(SHAREDCONTROL_CLUSTERID),   # Count the number of unique control groups within each study
         SHARED_CONTROL_N = CONTROL_N / SHAREDCONTROL_COUNT)   # Divide the sample size of each control (CONTROL_N) by the number of shared controls within its study

# Calculate an Effect Size (yi) and corresponding Sampling Variance (vi)
data.DQ <- escalc(measure="ROM",   # The effect size calculated will be log transformed ratio of means (metafor::escalc)
                     m1i=TREATMENT_MEAN,   # m1i = the treatment mean (e.g. dung+beetles or dung_only)
                     sd1i=TREATMENT_SD,   # sd1i = the treatment st.dev
                     n1i=TREATMENT_N,   # n1i = the treatment sample size
                     m2i=CONTROL_MEAN,   # m2i = the control mean (e.g. dung_only or soil_only)    
                     sd2i=CONTROL_SD,   # sd2i = the control st.dev  
                     n2i=SHARED_CONTROL_N,   # n2i = the control sample size (here we used our modified control sample size)
                     data=data.DQ,
                     slab=paste(STUDYID, YEAR, sep=", ")) # A warning incorrectly suggests that NANs produced
# Rename the Effect Size (yi) and corresponding Sampling Variance (vi)columns to make them more intuitive to read 
colnames(data.DQ)[which(names(data.DQ) == "yi")] <- "effect_size"   # The Effect Size column is now labelled 'effect_size'
colnames(data.DQ)[which(names(data.DQ) == "vi")] <- "effect_size_variance"   # The Sampling Variance is now labelled 'effect_size_variance'
# Calculate a standard error (sqrt(effect_size_variance)) and a precision value (1/standard error) (Bishop & Nakagawa, 2021)
data.DQ$se <- sqrt(data.DQ$effect_size_variance)
data.DQ$precision <- 1/data.DQ$se
# Make vcov matrices
variance.covariance.matrices.DQ <- 
  make_VCV_matrix(data = data.DQ,
                  V = "effect_size_variance",
                  cluster = "MULTIPLE_ENDPOINT_CLUSTERID",
                  obs = "ACCESSION_ID",
                  type = "vcv",
                  rho = assumed_variance)
is.positive.definite(variance.covariance.matrices.DQ)

# Again, arrange data.DQ by MULTIPLE_ENDPOINT_CLUSTERID (ascending)
data.DQ <- data.DQ[order(data.DQ$MULTIPLE_ENDPOINT_CLUSTERID), ]

# The RE.DQ model contains vcov matrices (it assumes non-dependence between effect sizes within studies)
RE.DQ <- rma.mv(yi = effect_size,
                   V = variance.covariance.matrices.DQ,
                   random = list(~1 | STUDYID, 
                                 ~1 | ACCESSION_ID), 
                   data = data.DQ, 
                   method = "ML")
summary(RE.DQ)
AIC(RE.DQ) #-42.00453

# Our model testing for DUNG_QUANTITY_IN_GRAMS as a moderator
RE.DQ.ml <- rma.mv(yi = effect_size,
                      V = variance.covariance.matrices.DQ,
                      mods = ~DUNG_QUANTITY_IN_GRAMS,
                      random = list(~1 | STUDYID,
                                    ~1 | ACCESSION_ID),
                      data = data.DQ,
                      method = "ML")
summary(RE.DQ.ml)
AIC(RE.DQ.ml) #-48.89823
anova(RE.DQ.ml, RE.DQ)   # Full is with moderator, Reduced is without (null)

```

```{r Results DUNG_QUANTITY_IN_GRAMS moderator}
#| echo: false
#| message: false

# Re-fit the model with REML for reporting estimates in the paper
RE.DQ.reml <- rma.mv(yi = effect_size,
                        V = variance.covariance.matrices.DQ,
                        mods = ~DUNG_QUANTITY_IN_GRAMS,
                        random = list(~1 | STUDYID,
                                      ~1 | ACCESSION_ID), 
                        data = data.DQ,
                        method = "REML")
summary(RE.DQ.reml)

# visualise results
pred_time <- predict.rma(RE.DQ.ml)
predict.rma(RE.DQ.ml,
            newmods = c(min(data.DQ$DUNG_QUANTITY_IN_GRAMS),
                        max(data.DQ$DUNG_QUANTITY_IN_GRAMS)))
data.DQ %>%
  mutate(ymin = pred_time$ci.lb,
         ymax = pred_time$ci.ub,
         ymin2 = pred_time$cr.lb,
         ymax2 = pred_time$cr.ub,
         pred = pred_time$pred) %>%
  ggplot(aes(x = DUNG_QUANTITY_IN_GRAMS,
             y = effect_size, size = sqrt(1/effect_size_variance))) +
  geom_point(shape = 21,
             fill = "grey90") + # geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = ’#0072B2’) + # not quite sure why this does not work
  geom_smooth(aes(y = ymin2),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#0072B2") +
  geom_smooth(aes(y = ymax2),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#0072B2") +
  geom_smooth(aes(y = ymin),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#D55E00") +
  geom_smooth(aes(y = ymax),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#D55E00") +
  geom_smooth(aes(y = pred),
              method = "loess",
              se = FALSE,
              lty = "dashed",
              lwd = 1,
              colour = "black") +
  labs(title = "Dung quantity influencing plant growth",
       x = "Dung (g)",
       y = "lnRR (effect size)",
       size = "Precision (1/SE)") + 
  guides(fill = "none",
         colour = "none") +
  theme_bw()+  
  theme(panel.background = element_rect(fill = "transparent", 
                                        color = NA),
        plot.background = element_rect(fill = "transparent", 
                                       color = NA),
        legend.background = element_rect(fill = "transparent"),
        legend.key = element_rect(fill = "transparent", 
                                  colour = NA))

```

**Dung quantity is influential to the overall estimate**, this is when outliers from Badenhorst et al. (2018) are included (LRT RE.DQ.ml vs RE.DQ, *p*=`r round((anova(RE.DQ.ml, RE.DQ)$pval), digits = 3)`), and removed (LRT RE.DQ.ml vs RE.DQ, *p*=0.0028).<br>
  With an assumed variance (rho) of 0.9 (LRT RE.DQ.ml vs RE.DQ, *p*=0.0025).<br>
  <br>


## Dung quantity (per surface area)
Some studies have an unknown dung quantity (per surface area) so we filter out those study outcomes with NAs listed for GRAMS_DUNG_PER_CM_SQUARED.<br>

```{r GRAMS_DUNG_PER_CM_SQUARED moderator}
#| include: false
#| warning: false

data.DQSA <- 
  data %>% 
  # Isolate the dung+beetles treatments with dung_only controls
  filter(TREATMENT == "dung+beetles",   # Isolate the "dung+beetles" treatments from the TREATMENT column
         CONTROL_TREATMENT == "dung_only") %>%    # AND isolate the "dung_only+beetles" treatments from the CONTROL_TREATMENT column   
  drop_na(GRAMS_DUNG_PER_CM_SQUARED) %>%   # And filter out the studies with NAs listed for the GRAMS_DUNG_PER_CM_SQUARED

  #filter(GRAMS_DUNG_PER_CM_SQUARED <= 2) %>%   ############## Remove the two outliers from Badenhorst et al., 2018 ##############  
  
# Filter out the studies that don't have the required measurements to calculate an effect size
drop_na(TREATMENT_N,
        TREATMENT_MEAN,
        TREATMENT_SD,
        CONTROL_N,
        CONTROL_MEAN,
        CONTROL_SD) %>%   # Remove all studies that have 'NA' recorded for any of the six measurements required to calculate an effect size
  group_by(STUDYID) %>%
  mutate(SHAREDCONTROL_COUNT = n_distinct(SHAREDCONTROL_CLUSTERID),   # Count the number of unique control groups within each study
         SHARED_CONTROL_N = CONTROL_N / SHAREDCONTROL_COUNT)   # Divide the sample size of each control (CONTROL_N) by the number of shared controls within its study

# Calculate an Effect Size (yi) and corresponding Sampling Variance (vi)
data.DQSA <- escalc(measure="ROM",   # The effect size calculated will be log transformed ratio of means (metafor::escalc)
                     m1i=TREATMENT_MEAN,   # m1i = the treatment mean (e.g. dung+beetles or dung_only)
                     sd1i=TREATMENT_SD,   # sd1i = the treatment st.dev
                     n1i=TREATMENT_N,   # n1i = the treatment sample size
                     m2i=CONTROL_MEAN,   # m2i = the control mean (e.g. dung_only or soil_only)    
                     sd2i=CONTROL_SD,   # sd2i = the control st.dev  
                     n2i=SHARED_CONTROL_N,   # n2i = the control sample size (here we used our modified control sample size)
                     data=data.DQSA,
                     slab=paste(STUDYID, YEAR, sep=", ")) # A warning incorrectly suggests that NANs produced
# Rename the Effect Size (yi) and corresponding Sampling Variance (vi)columns to make them more intuitive to read 
colnames(data.DQSA)[which(names(data.DQSA) == "yi")] <- "effect_size"   # The Effect Size column is now labelled 'effect_size'
colnames(data.DQSA)[which(names(data.DQSA) == "vi")] <- "effect_size_variance"   # The Sampling Variance is now labelled 'effect_size_variance'
# Calculate a standard error (sqrt(effect_size_variance)) and a precision value (1/standard error) (Bishop & Nakagawa, 2021)
data.DQSA$se <- sqrt(data.DQSA$effect_size_variance)
data.DQSA$precision <- 1/data.DQSA$se
# Make vcov matrices
variance.covariance.matrices.DQSA <- 
  make_VCV_matrix(data = data.DQSA,
                  V = "effect_size_variance",
                  cluster = "MULTIPLE_ENDPOINT_CLUSTERID",
                  obs = "ACCESSION_ID",
                  type = "vcv",
                  rho = assumed_variance)
is.positive.definite(variance.covariance.matrices.DQSA)

# Again, arrange data.DQSA by MULTIPLE_ENDPOINT_CLUSTERID (ascending)
data.DQSA <- data.DQSA[order(data.DQSA$MULTIPLE_ENDPOINT_CLUSTERID), ]

# The RE.DQSA model contains vcov matrices (it assumes non-dependence between effect sizes within studies)
RE.DQSA <- rma.mv(yi = effect_size,
                   V = variance.covariance.matrices.DQSA,
                   random = list(~1 | STUDYID, 
                                 ~1 | ACCESSION_ID), 
                   data = data.DQSA, 
                   method = "ML")
summary(RE.DQSA)
AIC(RE.DQSA) #-60.95213

# Our model testing for GRAMS_DUNG_PER_CM_SQUARED as a moderator
RE.DQSA.ml <- rma.mv(yi = effect_size,
                      V = variance.covariance.matrices.DQSA,
                      mods = ~GRAMS_DUNG_PER_CM_SQUARED,
                      random = list(~1 | STUDYID,
                                    ~1 | ACCESSION_ID),
                      data = data.DQSA,
                      method = "ML")
summary(RE.DQSA.ml)
AIC(RE.DQSA.ml) #-66.98038
anova(RE.DQSA.ml, RE.DQSA)   # Full is with moderator, Reduced is without (null)

```

```{r Results GRAMS_DUNG_PER_CM_SQUARED moderator}
#| echo: false
#| message: false

# Re-fit the model with REML for reporting estimates in the paper
RE.DQSA.reml <- rma.mv(yi = effect_size,
                        V = variance.covariance.matrices.DQSA,
                        mods = ~GRAMS_DUNG_PER_CM_SQUARED,
                        random = list(~1 | STUDYID,
                                      ~1 | ACCESSION_ID), 
                        data = data.DQSA,
                        method = "REML")
summary(RE.DQSA.reml)

# visualise results
pred_time <- predict.rma(RE.DQSA.ml)
predict.rma(RE.DQSA.ml,
            newmods = c(min(data.DQSA$GRAMS_DUNG_PER_CM_SQUARED),
                        max(data.DQSA$GRAMS_DUNG_PER_CM_SQUARED)))
data.DQSA %>%
  mutate(ymin = pred_time$ci.lb,
         ymax = pred_time$ci.ub,
         ymin2 = pred_time$cr.lb,
         ymax2 = pred_time$cr.ub,
         pred = pred_time$pred) %>%
  ggplot(aes(x = GRAMS_DUNG_PER_CM_SQUARED,
             y = effect_size, size = sqrt(1/effect_size_variance))) +
  geom_point(shape = 21,
             fill = "grey90") + # geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = ’#0072B2’) + # not quite sure why this does not work
  geom_smooth(aes(y = ymin2),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#0072B2") +
  geom_smooth(aes(y = ymax2),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#0072B2") +
  geom_smooth(aes(y = ymin),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#D55E00") +
  geom_smooth(aes(y = ymax),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#D55E00") +
  geom_smooth(aes(y = pred),
              method = "loess",
              se = FALSE,
              lty = "dashed",
              lwd = 1,
              colour = "black") +
  labs(title = "Dung quantity (per surface area) influencing plant growth",
       x = "Dung (g/cm^2)",
       y = "lnRR (effect size)",
       size = "Precision (1/SE)") + 
  guides(fill = "none",
         colour = "none") +
  theme_bw()+  
  theme(panel.background = element_rect(fill = "transparent", 
                                        color = NA),
        plot.background = element_rect(fill = "transparent", 
                                       color = NA),
        legend.background = element_rect(fill = "transparent"),
        legend.key = element_rect(fill = "transparent", 
                                  colour = NA))

```

**Dung quantity (per surface area) is influential to the overall estimate**, this is when outliers from Badenhorst et al. (2018) are included (LRT RE.DQSA.ml vs RE.DQSA, *p*=`r round((anova(RE.DQSA.ml, RE.DQSA)$pval), digits = 3)`), and removed (LRT RE.DQSA.ml vs RE.DQSA, *p*=0.0258).<br>
  With an assumed variance (rho) of 0.9 (LRT RE.DQSA.ml vs RE.DQSA, *p*=0.0046).<br>
  <br>


## Dung quantity (per beetle number)
Some studies have an unknown dung quantity (per beetle number) so we filter out those study outcomes with NAs listed for GRAMS_DUNG_PER_BEETLE_NUMBER.<br>

```{r GRAMS_DUNG_PER_BEETLE_NUMBER moderator}
#| include: false
#| warning: false

data.DQPBN <- 
  data %>% 
  # Isolate the dung+beetles treatments with dung_only controls
  filter(TREATMENT == "dung+beetles",   # Isolate the "dung+beetles" treatments from the TREATMENT column
         CONTROL_TREATMENT == "dung_only") %>%    # AND isolate the "dung_only+beetles" treatments from the CONTROL_TREATMENT column   
  drop_na(GRAMS_DUNG_PER_BEETLE_NUMBER) %>%   # And filter out the studies with NAs listed for the GRAMS_DUNG_PER_BEETLE_NUMBER

# Filter out the studies that don't have the required measurements to calculate an effect size
drop_na(TREATMENT_N,
        TREATMENT_MEAN,
        TREATMENT_SD,
        CONTROL_N,
        CONTROL_MEAN,
        CONTROL_SD) %>%   # Remove all studies that have 'NA' recorded for any of the six measurements required to calculate an effect size
  group_by(STUDYID) %>%
  mutate(SHAREDCONTROL_COUNT = n_distinct(SHAREDCONTROL_CLUSTERID),   # Count the number of unique control groups within each study
         SHARED_CONTROL_N = CONTROL_N / SHAREDCONTROL_COUNT)   # Divide the sample size of each control (CONTROL_N) by the number of shared controls within its study

# Calculate an Effect Size (yi) and corresponding Sampling Variance (vi)
data.DQPBN <- escalc(measure="ROM",   # The effect size calculated will be log transformed ratio of means (metafor::escalc)
                     m1i=TREATMENT_MEAN,   # m1i = the treatment mean (e.g. dung+beetles or dung_only)
                     sd1i=TREATMENT_SD,   # sd1i = the treatment st.dev
                     n1i=TREATMENT_N,   # n1i = the treatment sample size
                     m2i=CONTROL_MEAN,   # m2i = the control mean (e.g. dung_only or soil_only)    
                     sd2i=CONTROL_SD,   # sd2i = the control st.dev  
                     n2i=SHARED_CONTROL_N,   # n2i = the control sample size (here we used our modified control sample size)
                     data=data.DQPBN,
                     slab=paste(STUDYID, YEAR, sep=", ")) # A warning incorrectly suggests that NANs produced
# Rename the Effect Size (yi) and corresponding Sampling Variance (vi)columns to make them more intuitive to read 
colnames(data.DQPBN)[which(names(data.DQPBN) == "yi")] <- "effect_size"   # The Effect Size column is now labelled 'effect_size'
colnames(data.DQPBN)[which(names(data.DQPBN) == "vi")] <- "effect_size_variance"   # The Sampling Variance is now labelled 'effect_size_variance'
# Calculate a standard error (sqrt(effect_size_variance)) and a precision value (1/standard error) (Bishop & Nakagawa, 2021)
data.DQPBN$se <- sqrt(data.DQPBN$effect_size_variance)
data.DQPBN$precision <- 1/data.DQPBN$se
# Make vcov matrices
variance.covariance.matrices.DQPBN <- 
  make_VCV_matrix(data = data.DQPBN,
                  V = "effect_size_variance",
                  cluster = "MULTIPLE_ENDPOINT_CLUSTERID",
                  obs = "ACCESSION_ID",
                  type = "vcv",
                  rho = assumed_variance)
is.positive.definite(variance.covariance.matrices.DQPBN)

# Again, arrange data.DQPBN by MULTIPLE_ENDPOINT_CLUSTERID (ascending)
data.DQPBN <- data.DQPBN[order(data.DQPBN$MULTIPLE_ENDPOINT_CLUSTERID), ]

# The RE.DQPBN model contains vcov matrices (it assumes non-dependence between effect sizes within studies)
RE.DQPBN <- rma.mv(yi = effect_size,
                   V = variance.covariance.matrices.DQPBN,
                   random = list(~1 | STUDYID, 
                                 ~1 | ACCESSION_ID), 
                   data = data.DQPBN, 
                   method = "ML")
summary(RE.DQPBN)
AIC(RE.DQPBN) #-53.17293

# Our model testing for GRAMS_DUNG_PER_BEETLE_NUMBER as a moderator
RE.DQPBN.ml <- rma.mv(yi = effect_size,
                      V = variance.covariance.matrices.DQPBN,
                      mods = ~GRAMS_DUNG_PER_BEETLE_NUMBER,
                      random = list(~1 | STUDYID,
                                    ~1 | ACCESSION_ID),
                      data = data.DQPBN,
                      method = "ML")
summary(RE.DQPBN.ml)
AIC(RE.DQPBN.ml) #-51.1897
anova(RE.DQPBN.ml, RE.DQPBN)   # Full is with moderator, Reduced is without (null)

```

```{r Results GRAMS_DUNG_PER_BEETLE_NUMBER moderator}
#| include: false
#| message: false

# Re-fit the model with REML for reporting estimates in the paper
RE.DQPBN.reml <- rma.mv(yi = effect_size,
                        V = variance.covariance.matrices.DQPBN,
                        mods = ~GRAMS_DUNG_PER_BEETLE_NUMBER,
                        random = list(~1 | STUDYID,
                                      ~1 | ACCESSION_ID), 
                        data = data.DQPBN,
                        method = "REML")
summary(RE.DQPBN.reml)

# visualise results
pred_time <- predict.rma(RE.DQPBN.ml)
predict.rma(RE.DQPBN.ml,
            newmods = c(min(data.DQPBN$GRAMS_DUNG_PER_BEETLE_NUMBER),
                        max(data.DQPBN$GRAMS_DUNG_PER_BEETLE_NUMBER)))
data.DQPBN %>%
  mutate(ymin = pred_time$ci.lb,
         ymax = pred_time$ci.ub,
         ymin2 = pred_time$cr.lb,
         ymax2 = pred_time$cr.ub,
         pred = pred_time$pred) %>%
  ggplot(aes(x = GRAMS_DUNG_PER_BEETLE_NUMBER,
             y = effect_size, size = sqrt(1/effect_size_variance))) +
  geom_point(shape = 21,
             fill = "grey90") + # geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = ’#0072B2’) + # not quite sure why this does not work
  geom_smooth(aes(y = ymin2),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#0072B2") +
  geom_smooth(aes(y = ymax2),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#0072B2") +
  geom_smooth(aes(y = ymin),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#D55E00") +
  geom_smooth(aes(y = ymax),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#D55E00") +
  geom_smooth(aes(y = pred),
              method = "loess",
              se = FALSE,
              lty = "dashed",
              lwd = 1,
              colour = "black") +
  labs(title = "Dung quantity (per beetle number) influencing plant growth",
       x = "Dung (g/beetle number)",
       y = "lnRR (effect size)",
       size = "Precision (1/SE)") + 
  guides(fill = "none",
         colour = "none") +
  theme_bw()+  
  theme(panel.background = element_rect(fill = "transparent", 
                                        color = NA),
        plot.background = element_rect(fill = "transparent", 
                                       color = NA),
        legend.background = element_rect(fill = "transparent"),
        legend.key = element_rect(fill = "transparent", 
                                  colour = NA))

```

**Dung quantity (per beetle number) is not influential to the overall estimate** (LRT RE.DQPBN.ml vs RE.DQPBN, *p*=`r round((anova(RE.DQPBN.ml, RE.DQPBN)$pval), digits = 3)`).<br>
  With an assumed variance (rho) of 0.9 (LRT RE.DQPBN.ml vs RE.DQPBN, *p*=0.897).<br>
  <br>


## Dung quantity (per total beetle weight)
Some studies have an unknown dung quantity (per total beetle weight) so we filter out those study outcomes with NAs listed for GRAMS_DUNG_PER_BEETLE_WEIGHT.<br>

```{r GRAMS_DUNG_PER_BEETLE_WEIGHT moderator}
#| include: false
#| warning: false

data.DQPBW <- 
  data %>% 
  # Isolate the dung+beetles treatments with dung_only controls
  filter(TREATMENT == "dung+beetles",   # Isolate the "dung+beetles" treatments from the TREATMENT column
         CONTROL_TREATMENT == "dung_only") %>%    # AND isolate the "dung_only+beetles" treatments from the CONTROL_TREATMENT column   
  drop_na(GRAMS_DUNG_PER_BEETLE_WEIGHT) %>%   # And filter out the studies with NAs listed for the GRAMS_DUNG_PER_BEETLE_WEIGHT

# Filter out the studies that don't have the required measurements to calculate an effect size
drop_na(TREATMENT_N,
        TREATMENT_MEAN,
        TREATMENT_SD,
        CONTROL_N,
        CONTROL_MEAN,
        CONTROL_SD) %>%   # Remove all studies that have 'NA' recorded for any of the six measurements required to calculate an effect size
  group_by(STUDYID) %>%
  mutate(SHAREDCONTROL_COUNT = n_distinct(SHAREDCONTROL_CLUSTERID),   # Count the number of unique control groups within each study
         SHARED_CONTROL_N = CONTROL_N / SHAREDCONTROL_COUNT)   # Divide the sample size of each control (CONTROL_N) by the number of shared controls within its study

# Calculate an Effect Size (yi) and corresponding Sampling Variance (vi)
data.DQPBW <- escalc(measure="ROM",   # The effect size calculated will be log transformed ratio of means (metafor::escalc)
                     m1i=TREATMENT_MEAN,   # m1i = the treatment mean (e.g. dung+beetles or dung_only)
                     sd1i=TREATMENT_SD,   # sd1i = the treatment st.dev
                     n1i=TREATMENT_N,   # n1i = the treatment sample size
                     m2i=CONTROL_MEAN,   # m2i = the control mean (e.g. dung_only or soil_only)    
                     sd2i=CONTROL_SD,   # sd2i = the control st.dev  
                     n2i=SHARED_CONTROL_N,   # n2i = the control sample size (here we used our modified control sample size)
                     data=data.DQPBW,
                     slab=paste(STUDYID, YEAR, sep=", ")) # A warning incorrectly suggests that NANs produced
# Rename the Effect Size (yi) and corresponding Sampling Variance (vi)columns to make them more intuitive to read 
colnames(data.DQPBW)[which(names(data.DQPBW) == "yi")] <- "effect_size"   # The Effect Size column is now labelled 'effect_size'
colnames(data.DQPBW)[which(names(data.DQPBW) == "vi")] <- "effect_size_variance"   # The Sampling Variance is now labelled 'effect_size_variance'
# Calculate a standard error (sqrt(effect_size_variance)) and a precision value (1/standard error) (Bishop & Nakagawa, 2021)
data.DQPBW$se <- sqrt(data.DQPBW$effect_size_variance)
data.DQPBW$precision <- 1/data.DQPBW$se
# Make vcov matrices
variance.covariance.matrices.DQPBW <- 
  make_VCV_matrix(data = data.DQPBW,
                  V = "effect_size_variance",
                  cluster = "MULTIPLE_ENDPOINT_CLUSTERID",
                  obs = "ACCESSION_ID",
                  type = "vcv",
                  rho = assumed_variance)
is.positive.definite(variance.covariance.matrices.DQPBW)

# Again, arrange data.DQPBW by MULTIPLE_ENDPOINT_CLUSTERID (ascending)
data.DQPBW <- data.DQPBW[order(data.DQPBW$MULTIPLE_ENDPOINT_CLUSTERID), ]

# The RE.DQPBW model contains vcov matrices (it assumes non-dependence between effect sizes within studies)
RE.DQPBW <- rma.mv(yi = effect_size,
                   V = variance.covariance.matrices.DQPBW,
                   random = list(~1 | STUDYID, 
                                 ~1 | ACCESSION_ID), 
                   data = data.DQPBW, 
                   method = "ML")
summary(RE.DQPBW)
AIC(RE.DQPBW) #-16.54977

# Our model testing for GRAMS_DUNG_PER_BEETLE_WEIGHT as a moderator
RE.DQPBW.ml <- rma.mv(yi = effect_size,
                      V = variance.covariance.matrices.DQPBW,
                      mods = ~GRAMS_DUNG_PER_BEETLE_WEIGHT,
                      random = list(~1 | STUDYID,
                                    ~1 | ACCESSION_ID),
                      data = data.DQPBW,
                      method = "ML")
summary(RE.DQPBW.ml)
AIC(RE.DQPBW.ml) #-14.58575
anova(RE.DQPBW.ml, RE.DQPBW)   # Full is with moderator, Reduced is without (null)

```

```{r Results GRAMS_DUNG_PER_BEETLE_WEIGHT moderator}
#| include: false
#| message: false

# Re-fit the model with REML for reporting estimates in the paper
RE.DQPBW.reml <- rma.mv(yi = effect_size,
                        V = variance.covariance.matrices.DQPBW,
                        mods = ~GRAMS_DUNG_PER_BEETLE_WEIGHT,
                        random = list(~1 | STUDYID,
                                      ~1 | ACCESSION_ID), 
                        data = data.DQPBW,
                        method = "REML")
summary(RE.DQPBW.reml)

# visualise results
pred_time <- predict.rma(RE.DQPBW.ml)
predict.rma(RE.DQPBW.ml,
            newmods = c(min(data.DQPBW$GRAMS_DUNG_PER_BEETLE_WEIGHT),
                        max(data.DQPBW$GRAMS_DUNG_PER_BEETLE_WEIGHT)))
data.DQPBW %>%
  mutate(ymin = pred_time$ci.lb,
         ymax = pred_time$ci.ub,
         ymin2 = pred_time$cr.lb,
         ymax2 = pred_time$cr.ub,
         pred = pred_time$pred) %>%
  ggplot(aes(x = GRAMS_DUNG_PER_BEETLE_WEIGHT,
             y = effect_size, size = sqrt(1/effect_size_variance))) +
  geom_point(shape = 21,
             fill = "grey90") + # geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = ’#0072B2’) + # not quite sure why this does not work
  geom_smooth(aes(y = ymin2),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#0072B2") +
  geom_smooth(aes(y = ymax2),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#0072B2") +
  geom_smooth(aes(y = ymin),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#D55E00") +
  geom_smooth(aes(y = ymax),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#D55E00") +
  geom_smooth(aes(y = pred),
              method = "loess",
              se = FALSE,
              lty = "dashed",
              lwd = 1,
              colour = "black") +
  labs(title = "Dung quantity (per total beetle weight) influencing plant growth",
       x = "Dung (g/total beetle weight (mg))",
       y = "lnRR (effect size)",
       size = "Precision (1/SE)") + 
  guides(fill = "none",
         colour = "none") +
  theme_bw()+  
  theme(panel.background = element_rect(fill = "transparent", 
                                        color = NA),
        plot.background = element_rect(fill = "transparent", 
                                       color = NA),
        legend.background = element_rect(fill = "transparent"),
        legend.key = element_rect(fill = "transparent", 
                                  colour = NA))

```

**Dung quantity (per total beetle weight) is not influential to the overall estimate** (LRT RE.DQPBW.ml vs RE.DQPBW, *p*=`r round((anova(RE.DQPBW.ml, RE.DQPBW)$pval), digits = 3)`).<br>
  With an assumed variance (rho) of 0.9 (LRT RE.DQPBW.ml vs RE.DQPBW, *p*=0.85).<br>
  <br>


## Plant clade
Is the clade of plant used in the experiment (monocot, dicot or both) influential?<br>

```{r CLADE moderator}
#| include: false
#| warning: false

# Our original/null model (maximum likelihood (RE), not restricted maximum likelihood (RE.reml))
summary(RE)

# Our model testing for CLADE as a moderator
RE.CLADE.ml <- rma.mv(yi = effect_size,
                                 V = variance.covariance.matrices,
                                 mods = ~CLADE - 1,
                                 random = list(~1 | STUDYID,
                                               ~1 | ACCESSION_ID),
                                 data = data1,
                                 method = "ML")
anova(RE.CLADE.ml, RE)   # Full is with moderator, Reduced is without (null)

```

```{r Results CLADE moderator}
#| include: false

# Re-fit the model with REML for reporting estimates in the paper
RE.CLADE.reml <- rma.mv(yi = effect_size,
                           V = variance.covariance.matrices,
                           mods = ~CLADE - 1,
                           random = list(~1 | STUDYID,
                                         ~1 | ACCESSION_ID),
                           data = data1,
                           method = "REML")
summary(RE.CLADE.reml)

```

**Plant clade is not influential to the overall estimate** (LRT RE.CLADE.ml vs RE, *p*=`r round((anova(RE.CLADE.ml, RE)$pval), digits = 3)`).<br>
<br>


## Plants germinated before dung addition
Was the timing of dung addition important (either before or after plants had germinated)?<br>

```{r PLANTS_GERMINATED_BEFORE_DUNG_ADDITION moderator}
#| include: false
#| warning: false

# Our original/null model (maximum likelihood (RE), not restricted maximum likelihood (RE.reml))
summary(RE)

# Our model testing for PLANTS_GERMINATED_BEFORE_DUNG_ADDITION as a moderator
RE.PLANTS_GERMINATED_BEFORE_DUNG_ADDITION.ml <- rma.mv(yi = effect_size,
                                                       V = variance.covariance.matrices,
                                                       mods = ~PLANTS_GERMINATED_BEFORE_DUNG_ADDITION - 1,
                                                       random = list(~1 | STUDYID,
                                                                     ~1 | ACCESSION_ID),
                                                       data = data1,
                                                       method = "ML")
anova(RE.PLANTS_GERMINATED_BEFORE_DUNG_ADDITION.ml, RE)   # Full is with moderator, Reduced is without (null)

# Re-fit the model with REML for reporting estimates in the paper
RE.PLANTS_GERMINATED_BEFORE_DUNG_ADDITION.reml <- 
                           rma.mv(yi = effect_size,
                           V = variance.covariance.matrices,
                           mods = ~PLANTS_GERMINATED_BEFORE_DUNG_ADDITION - 1,
                           random = list(~1 | STUDYID,
                                         ~1 | ACCESSION_ID),
                           data = data1,
                           method = "REML")

```

```{r Results PLANTS_GERMINATED_BEFORE_DUNG_ADDITION moderator}
#| include: false

summary (RE.PLANTS_GERMINATED_BEFORE_DUNG_ADDITION.reml)

RE.PLANTS_GERMINATED_BEFORE_DUNG_ADDITION.reml.res <- 
                      mod_results(RE.PLANTS_GERMINATED_BEFORE_DUNG_ADDITION.reml,
                                  group = "STUDYID",
                                  data = data1,
                                  mod = "PLANTS_GERMINATED_BEFORE_DUNG_ADDITION")

PLANTS_GERMINATED_BEFORE_DUNG_ADDITION.plot <- 
  orchard_plot(RE.PLANTS_GERMINATED_BEFORE_DUNG_ADDITION.reml.res,
               mod = "1",
               group = "STUDYID",
               data = data1,
               xlab ="lnRR (effect size)") +
  labs(title = "Timing of dung addition influencing effect size",
       x = "Plants germinated before dung addition")
PLANTS_GERMINATED_BEFORE_DUNG_ADDITION.plot

```

**Plants germinated before dung addition is not influential to the overall estimate** (LRT RE.PLANTS_GERMINATED_BEFORE_DUNG_ADDITION.ml vs RE, *p*=`r round((anova(RE.PLANTS_GERMINATED_BEFORE_DUNG_ADDITION.ml, RE)$pval), digits = 3)`).<br>
Plants germinated before dung addition is slightly influential with assumed correlation (rho) of 0.9 (LRT RE.PLANTS_GERMINATED_BEFORE_DUNG_ADDITION.ml, RE, *p*=0.0791).<br>
<br>


## Days of plant growth 
Was the length of plant growth influential?<br>

```{r DAYS_OF_PLANT_GROWTH moderator}
#| include: false

# Our original/null model (maximum likelihood (RE), not restricted maximum likelihood (RE.reml))
summary(RE)

# Our model testing for DAYS_OF_PLANT_GROWTH as a moderator
RE.DAYS_OF_PLANT_GROWTH.ml <- rma.mv(yi = effect_size,
                                     V = variance.covariance.matrices,
                                     mods = ~DAYS_OF_PLANT_GROWTH,
                                     random = list(~1 | STUDYID,
                                                   ~1 | ACCESSION_ID),
                                     data = data1,
                                     method = "ML")
anova(RE.DAYS_OF_PLANT_GROWTH.ml, RE)   # Full is with moderator, Reduced is without (null)

# Re-fit the model with REML for reporting estimates in the paper
RE.DAYS_OF_PLANT_GROWTH.reml <- rma.mv(yi = effect_size,
                                       V = variance.covariance.matrices,
                                       mods = ~DAYS_OF_PLANT_GROWTH,
                                       random = list(~1 | STUDYID,
                                                     ~1 | ACCESSION_ID),
                                       data = data1,
                                       method = "REML")


```

```{r Results DAYS_OF_PLANT_GROWTH moderator}
#| include: false
#| message: false

summary(RE.DAYS_OF_PLANT_GROWTH.reml)

# visualise results
pred_time <- predict.rma(RE.DAYS_OF_PLANT_GROWTH.ml)
predict.rma(RE.DAYS_OF_PLANT_GROWTH.ml,
            newmods = c(min(data1$DAYS_OF_PLANT_GROWTH),
                        max(data1$DAYS_OF_PLANT_GROWTH)))
  data1 %>%
  mutate(ymin = pred_time$ci.lb,
         ymax = pred_time$ci.ub,
         ymin2 = pred_time$cr.lb,
         ymax2 = pred_time$cr.ub,
         pred = pred_time$pred) %>%
  ggplot(aes(x = DAYS_OF_PLANT_GROWTH,
             y = effect_size, size = sqrt(1/effect_size_variance))) +
  geom_point(shape = 21,
             fill = "grey90") + # geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = ’#0072B2’) + # not quite sure why this does not work
  geom_smooth(aes(y = ymin2),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#0072B2") +
  geom_smooth(aes(y = ymax2),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#0072B2") +
  geom_smooth(aes(y = ymin),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#D55E00") +
  geom_smooth(aes(y = ymax),
              method = "loess",
              se = FALSE,
              lty = "dotted",
              lwd = 0.75,
              colour = "#D55E00") +
  geom_smooth(aes(y = pred),
              method = "loess",
              se = FALSE,
              lty = "dashed",
              lwd = 1,
              colour = "black") +
  labs(title = "Days of plant growth influencing effect size",
       x = "Days of plant growth",
       y = "lnRR (effect size)",
       size = "Precision (1/SE)") + 
  guides(fill = "none",
         colour = "none") +
  theme_bw()+  
  theme(panel.background = element_rect(fill = "transparent", 
                                        color = NA),
        plot.background = element_rect(fill = "transparent", 
                                       color = NA),
        legend.background = element_rect(fill = "transparent"),
        legend.key = element_rect(fill = "transparent", 
                                  colour = NA))

```

**Days of plant growth is slightly influential to the overall estimate** (LRT RE.DAYS_OF_PLANT_GROWTH.ml vs RE, *p*=`r round((anova(RE.DAYS_OF_PLANT_GROWTH.ml, RE)$pval), digits = 3)`).<br>
Plants germinated before dung addition is slightly influential with assumed correlation (rho) of 0.9 (LRT RE.DAYS_OF_PLANT_GROWTH.ml, RE, *p*=0.0953).<br>
<br>
<br>


## Publication bias

Next we check for publication bias, which Nakagawa et al. (2017) recommend doing with more than one source .<br>
Firstly we produce a funnel plot, which includes the influential FUNCTIONAL_GROUP moderator.<br>
Nakagawa & Lagisz (2016) give brief instructions on interpreting a funnel plot.<br>
**NOTE: This may have to be re-done with all the influential moderators**<br>

```{r Funnel plot without moderators}
#| echo: false
#| warning: false

funnel(RE.FG.reml,
       yaxis = "seinv",   # The measure of precision for the y-axis
       level = c(90, 95, 99),
       shade = c("white", "gray55", "gray75"),
       main = NULL,   # Main title
       legend = TRUE,
       back	= "transparent",   # colour to use for the background of the plotting region
       hlines = "lightgray",   # colour of the horizontal reference lines
       col = "black",   # specify point colour
       bg = "transparent")   # specify the background colour for the plot

```

As a second assessment of publication bias, we use Egger's regression (see Egger et al. (1997)), with the standard error, SE (sqrt(effect_size_variance)) as a moderator. A significant slope for SE indicates statistically significant funnel asymmetry after controlling for all other variables in the model (Bishop & Nakagawa, 2021).<br>

```{r Eggers test}
#| echo: false
#| warning: false

# sqrt(effect_size_variance) = sampling standard error

egger <- rma.mv(yi = effect_size,
                V = variance.covariance.matrices,
                mods = sqrt(effect_size_variance),
                random = list(~1 | STUDYID,
                              ~1 | ACCESSION_ID),
                data = data1,
                method = "REML")
summary(egger) # If sqrt(effect_size_variance) moderator is statistically significant it suggests publication bias

```

The slope for SE (sqrt(effect_size_variance)) is non-significant *p*=`r round((summary(egger)$pval[2]), digits = 3)`, indicating a lack of publication bias.<br>

Now to visualise the Egger's regression.<br>
Each point represents the scaled individual effect size of a study outcome. The dashed black line is the predicted loess line for the SE (sqrt(effect_size_variance)) variable/moderator. The orange lines represent the 95% confidence region and the blue lines represent the 95% prediction region.<br>


```{r visualise Eggers test}
#| echo: false
#| message: false
#| warning: false

egger_predict <- predict.rma(egger)
figure_eggers <- data1 %>% 
  mutate(ymin = egger_predict$ci.lb, 
         ymax = egger_predict$ci.ub,
         ymin2 = egger_predict$cr.lb, 
         ymax2 = egger_predict$cr.ub, 
         pred = egger_predict$pred) %>%
ggplot(aes(x = sqrt(effect_size_variance), 
           y = effect_size, size = sqrt(1/effect_size_variance))) + 
  geom_point(shape = 21,
             fill = (values=wes_colours[2])) + 
  geom_smooth(aes(y = ymin2), 
              method = "loess",
              se = FALSE, 
              lty = "dotted", 
              lwd = 0.75, 
              colour = "#0072B2") +
  geom_smooth(aes(y = ymax2), 
              method = "loess", 
              se = FALSE,
              lty = "dotted", 
              lwd = 0.75, 
              colour = "#0072B2") + 
  geom_smooth(aes(y = ymin),
              method = "loess", 
              se = FALSE, 
              lty = "dotted", 
              lwd = 0.75,
              colour = "#D55E00") + 
  geom_smooth(aes(y = ymax), 
              method = "loess",
              se = FALSE, 
              lty = "dotted", 
              lwd = 0.75, 
              colour = "#D55E00") +
  geom_smooth(aes(y = pred), 
              method = "loess", 
              se = FALSE,
              lty = "dashed", 
              lwd = 1, 
              colour = "black") + 
  labs(x = "sqrt(sampling variance)",
       y = "lnRR (effect size)", 
       size = "Precision (1/SE)") + 
  guides(fill = "none",
         colour = "none") + # themes
  theme_bw()+  
  theme(panel.background = element_rect(fill = "transparent", 
                                        color = NA),
        plot.background = element_rect(fill = "transparent", 
                                       color = NA),
        legend.background = element_rect(fill = "transparent"),
        legend.key = element_rect(fill = "transparent", 
                                  colour = NA))
figure_eggers
ggsave(filename = (here("figures/eggers_plot.png")),
       plot = figure_eggers,
       bg = "transparent")

```


## References:
Bishop, J., & Nakagawa, S. (2021). Quantifying crop pollinator dependence and its heterogeneity using multi-level meta-analysis. Journal of Applied Ecology, 58(5), 1030–1042. https://doi.org/10.1111/1365-2664.13830<br>
Dougherty, L. R., Skirrow, M. J. A., Jennions, M. D., & Simmons, L. W. (2022). Male alternative reproductive tactics and sperm competition: a meta-analysis. Biological Reviews, 97, 1365–1388. https://doi.org/10.1111/brv.12846<br>
Hedges, L.V., Gurevitch, J. and Curtis, P.S. (1999), THE META-ANALYSIS OF RESPONSE RATIOS IN EXPERIMENTAL ECOLOGY. Ecology, 80: 1150-1156. https://doi.org/10.1890/0012-9658(1999)080[1150:TMAORR]2.0.CO;2
Johnson, S. N., Lopaticki, G., Barnett, K., Facey, S. L., Powell, J. R., & Hartley, S. E. (2016). An insect ecosystem engineer alleviates drought stress in plants without increasing plant susceptibility to an above-ground herbivore. Functional Ecology, 30(6), 894–902. https://doi.org/10.1111/1365-2435.12582<br>
Manning, P., Slade, E. M., Beynon, S. A., & Lewis, O. T. (2017). Effect of dung beetle species richness and chemical perturbation on multiple ecosystem functions. Ecological Entomology, 42(5), 577–586. https://doi.org/10.1111/een.12421<br>
Miranda, C. H. B., Santos, J. C. C., & Bianchin, I. (1998). Contribuição de Onthophagus gazella à melhoria da fertilidade do solo pelo enterrio de massa fecal bovina fresca. Brazilian Journal of Animal Science, 27, 681–685.<br>
Nakagawa, S., & Lagisz, M. (2016). Visualizing unbiased and biased unweighted meta-analyses. Journal of Evolutionary Biology, 29(10), 1914–1916. https://doi.org/10.1111/jeb.12945<br>
Nakagawa, Shinichi, & Santos, E. S. A. (2012). Methodological issues and advances in biological meta-analysis. Evolutionary Ecology, 26(5), 1253–1274. https://doi.org/10.1007/s10682-012-9555-5<br>
Nervo, B., Caprio, E., Celi, L., Lonati, M., Lombardi, G., Falsone, G., Iussig, G., Palestrini, C., Said-Pullicino, D., & Rolando, A. (2017). Ecological functions provided by dung beetles are interlinked across space and time: Evidence from 15N isotope tracing. Ecology, 98(2), 433–446. https://doi.org/10.1002/ecy.1653<br>
Noble, D. W. A., Lagisz, M., O’dea, R. E., & Nakagawa, S. (2017). Nonindependence and sensitivity analyses in ecological and evolutionary meta‐analyses. Molecular Ecology, 26, 2410–2425. https://doi.org/doi.org/10.1111/mec.14031<br>
Page, M. J., McKenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffmann, T. C., Mulrow, C. D., Shamseer, L., Tetzlaff, J. M., Akl, E. A., Brennan, S. E., Chou, R., Glanville, J., Grimshaw, J. M., Hróbjartsson, A., Lalu, M. M., Li, T., Loder, E. W., Mayo-Wilson, E., McDonald, S., … Moher, D. (2021). The PRISMA 2020 statement: An updated guideline for reporting systematic reviews. The BMJ, 372. https://doi.org/10.1136/bmj.n71<br>
Spineli, L. M., & Pandis, N. (2020). Prediction interval in random-effects meta-analysis. American Journal of Orthodontics and Dentofacial Orthopedics, 157(4), 586–588. https://doi.org/10.1016/j.ajodo.2019.12.011<br>
Viechtbauer, W. (2010). Conducting meta-analyses in {R} with the {metafor} package. Journal of Statistical Software, 36(3), 1–48. https://doi.org/10.18637/jss.v036.i03<br>